{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1c15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('updated_coughvid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2650c66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spec_cent</th>\n",
       "      <th>spec_bw</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zcr</th>\n",
       "      <th>mfcc{1}</th>\n",
       "      <th>mfcc{2}</th>\n",
       "      <th>mfcc{3}</th>\n",
       "      <th>mfcc{4}</th>\n",
       "      <th>...</th>\n",
       "      <th>rapJitter</th>\n",
       "      <th>ppq5Jitter</th>\n",
       "      <th>ddpJitter</th>\n",
       "      <th>localShimmer</th>\n",
       "      <th>localdbShimmer</th>\n",
       "      <th>apq3Shimmer</th>\n",
       "      <th>aqpq5Shimmer</th>\n",
       "      <th>apq11Shimmer</th>\n",
       "      <th>ddaShimmer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065850</td>\n",
       "      <td>0.403767</td>\n",
       "      <td>1316.806414</td>\n",
       "      <td>1373.998076</td>\n",
       "      <td>2637.860622</td>\n",
       "      <td>0.057043</td>\n",
       "      <td>-396.59204</td>\n",
       "      <td>69.540160</td>\n",
       "      <td>2.152846</td>\n",
       "      <td>13.354017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021518</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.064553</td>\n",
       "      <td>0.187378</td>\n",
       "      <td>1.718899</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>0.143649</td>\n",
       "      <td>0.352439</td>\n",
       "      <td>0.267473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033997</td>\n",
       "      <td>0.532892</td>\n",
       "      <td>2474.234037</td>\n",
       "      <td>2125.162327</td>\n",
       "      <td>4869.731365</td>\n",
       "      <td>0.186172</td>\n",
       "      <td>-435.21085</td>\n",
       "      <td>45.288998</td>\n",
       "      <td>-12.166409</td>\n",
       "      <td>10.258451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.042043</td>\n",
       "      <td>0.130333</td>\n",
       "      <td>1.313323</td>\n",
       "      <td>0.049385</td>\n",
       "      <td>0.059807</td>\n",
       "      <td>0.110768</td>\n",
       "      <td>0.148156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023310</td>\n",
       "      <td>0.370873</td>\n",
       "      <td>2158.381678</td>\n",
       "      <td>2007.817231</td>\n",
       "      <td>4750.294555</td>\n",
       "      <td>0.125032</td>\n",
       "      <td>-412.62552</td>\n",
       "      <td>54.555480</td>\n",
       "      <td>-1.768253</td>\n",
       "      <td>3.977824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>0.037981</td>\n",
       "      <td>0.100577</td>\n",
       "      <td>0.272967</td>\n",
       "      <td>2.125802</td>\n",
       "      <td>0.132889</td>\n",
       "      <td>0.196880</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.398668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047035</td>\n",
       "      <td>0.479319</td>\n",
       "      <td>2678.491315</td>\n",
       "      <td>2139.232294</td>\n",
       "      <td>5136.450596</td>\n",
       "      <td>0.246256</td>\n",
       "      <td>-393.00226</td>\n",
       "      <td>48.030190</td>\n",
       "      <td>-29.901045</td>\n",
       "      <td>25.478853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>0.031223</td>\n",
       "      <td>0.096085</td>\n",
       "      <td>0.175612</td>\n",
       "      <td>1.617597</td>\n",
       "      <td>0.070595</td>\n",
       "      <td>0.094968</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.211784</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011785</td>\n",
       "      <td>0.741700</td>\n",
       "      <td>3316.010424</td>\n",
       "      <td>2345.969321</td>\n",
       "      <td>6007.887783</td>\n",
       "      <td>0.278178</td>\n",
       "      <td>-556.18726</td>\n",
       "      <td>10.974088</td>\n",
       "      <td>-10.207122</td>\n",
       "      <td>6.857212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>0.069803</td>\n",
       "      <td>0.138516</td>\n",
       "      <td>1.320449</td>\n",
       "      <td>0.075879</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>0.227636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.429203</td>\n",
       "      <td>2974.741815</td>\n",
       "      <td>2265.905377</td>\n",
       "      <td>5435.183318</td>\n",
       "      <td>0.216093</td>\n",
       "      <td>-424.03302</td>\n",
       "      <td>38.712093</td>\n",
       "      <td>-16.247238</td>\n",
       "      <td>12.712377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029542</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>0.202130</td>\n",
       "      <td>1.619779</td>\n",
       "      <td>0.075903</td>\n",
       "      <td>0.199575</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.227709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24438</th>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.535591</td>\n",
       "      <td>2719.621677</td>\n",
       "      <td>2132.117936</td>\n",
       "      <td>5260.719083</td>\n",
       "      <td>0.198633</td>\n",
       "      <td>-471.09518</td>\n",
       "      <td>28.604359</td>\n",
       "      <td>-8.991700</td>\n",
       "      <td>12.397835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>0.059816</td>\n",
       "      <td>0.176616</td>\n",
       "      <td>1.347352</td>\n",
       "      <td>0.107413</td>\n",
       "      <td>0.148694</td>\n",
       "      <td>0.117848</td>\n",
       "      <td>0.322239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24439</th>\n",
       "      <td>0.159654</td>\n",
       "      <td>0.389324</td>\n",
       "      <td>2360.664509</td>\n",
       "      <td>1696.391140</td>\n",
       "      <td>4114.219514</td>\n",
       "      <td>0.169187</td>\n",
       "      <td>-206.32933</td>\n",
       "      <td>59.016940</td>\n",
       "      <td>-74.789270</td>\n",
       "      <td>-1.210189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>0.058168</td>\n",
       "      <td>0.164419</td>\n",
       "      <td>1.429379</td>\n",
       "      <td>0.093083</td>\n",
       "      <td>0.119234</td>\n",
       "      <td>0.175221</td>\n",
       "      <td>0.279249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24440</th>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.451451</td>\n",
       "      <td>2788.705294</td>\n",
       "      <td>1800.585083</td>\n",
       "      <td>4708.568653</td>\n",
       "      <td>0.239603</td>\n",
       "      <td>-469.87784</td>\n",
       "      <td>59.399067</td>\n",
       "      <td>-41.076590</td>\n",
       "      <td>-2.028796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032847</td>\n",
       "      <td>0.036794</td>\n",
       "      <td>0.098542</td>\n",
       "      <td>0.205180</td>\n",
       "      <td>1.715662</td>\n",
       "      <td>0.105993</td>\n",
       "      <td>0.139264</td>\n",
       "      <td>0.166415</td>\n",
       "      <td>0.317979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24441</th>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>951.673749</td>\n",
       "      <td>828.363544</td>\n",
       "      <td>1897.664311</td>\n",
       "      <td>0.050561</td>\n",
       "      <td>-587.85986</td>\n",
       "      <td>24.133877</td>\n",
       "      <td>-4.841230</td>\n",
       "      <td>9.684202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028159</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.084477</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>1.495134</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.021235</td>\n",
       "      <td>0.143348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24442 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rmse  chroma_stft    spec_cent      spec_bw      rolloff       zcr  \\\n",
       "0      0.065850     0.403767  1316.806414  1373.998076  2637.860622  0.057043   \n",
       "1      0.033997     0.532892  2474.234037  2125.162327  4869.731365  0.186172   \n",
       "2      0.023310     0.370873  2158.381678  2007.817231  4750.294555  0.125032   \n",
       "3      0.047035     0.479319  2678.491315  2139.232294  5136.450596  0.246256   \n",
       "4      0.011785     0.741700  3316.010424  2345.969321  6007.887783  0.278178   \n",
       "...         ...          ...          ...          ...          ...       ...   \n",
       "24437  0.030827     0.429203  2974.741815  2265.905377  5435.183318  0.216093   \n",
       "24438  0.030711     0.535591  2719.621677  2132.117936  5260.719083  0.198633   \n",
       "24439  0.159654     0.389324  2360.664509  1696.391140  4114.219514  0.169187   \n",
       "24440  0.030981     0.451451  2788.705294  1800.585083  4708.568653  0.239603   \n",
       "24441  0.007046     0.167502   951.673749   828.363544  1897.664311  0.050561   \n",
       "\n",
       "         mfcc{1}    mfcc{2}    mfcc{3}    mfcc{4}  ...  rapJitter  ppq5Jitter  \\\n",
       "0     -396.59204  69.540160   2.152846  13.354017  ...   0.021518    0.024053   \n",
       "1     -435.21085  45.288998 -12.166409  10.258451  ...   0.014014    0.018379   \n",
       "2     -412.62552  54.555480  -1.768253   3.977824  ...   0.033526    0.037981   \n",
       "3     -393.00226  48.030190 -29.901045  25.478853  ...   0.032028    0.031223   \n",
       "4     -556.18726  10.974088 -10.207122   6.857212  ...   0.023268    0.026566   \n",
       "...          ...        ...        ...        ...  ...        ...         ...   \n",
       "24437 -424.03302  38.712093 -16.247238  12.712377  ...   0.029542    0.036789   \n",
       "24438 -471.09518  28.604359  -8.991700  12.397835  ...   0.019939    0.022426   \n",
       "24439 -206.32933  59.016940 -74.789270  -1.210189  ...   0.019389    0.020776   \n",
       "24440 -469.87784  59.399067 -41.076590  -2.028796  ...   0.032847    0.036794   \n",
       "24441 -587.85986  24.133877  -4.841230   9.684202  ...   0.028159    0.037088   \n",
       "\n",
       "       ddpJitter  localShimmer  localdbShimmer  apq3Shimmer  aqpq5Shimmer  \\\n",
       "0       0.064553      0.187378        1.718899     0.089158      0.143649   \n",
       "1       0.042043      0.130333        1.313323     0.049385      0.059807   \n",
       "2       0.100577      0.272967        2.125802     0.132889      0.196880   \n",
       "3       0.096085      0.175612        1.617597     0.070595      0.094968   \n",
       "4       0.069803      0.138516        1.320449     0.075879      0.081973   \n",
       "...          ...           ...             ...          ...           ...   \n",
       "24437   0.088625      0.202130        1.619779     0.075903      0.199575   \n",
       "24438   0.059816      0.176616        1.347352     0.107413      0.148694   \n",
       "24439   0.058168      0.164419        1.429379     0.093083      0.119234   \n",
       "24440   0.098542      0.205180        1.715662     0.105993      0.139264   \n",
       "24441   0.084477      0.119565        1.495134     0.047783      0.049730   \n",
       "\n",
       "       apq11Shimmer  ddaShimmer  label  \n",
       "0          0.352439    0.267473      0  \n",
       "1          0.110768    0.148156      1  \n",
       "2          0.160610    0.398668      1  \n",
       "3          0.154762    0.211784      0  \n",
       "4          0.145956    0.227636      0  \n",
       "...             ...         ...    ...  \n",
       "24437      0.160610    0.227709      1  \n",
       "24438      0.117848    0.322239      1  \n",
       "24439      0.175221    0.279249      0  \n",
       "24440      0.166415    0.317979      1  \n",
       "24441      0.021235    0.143348      0  \n",
       "\n",
       "[24442 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8956417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef70d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e06694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e85b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for use in a CNN model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ddb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f935251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4545e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.8925 - accuracy: 0.6865 - val_loss: 0.9887 - val_accuracy: 0.6731\n",
      "Epoch 2/50\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.6504 - accuracy: 0.7773 - val_loss: 0.5266 - val_accuracy: 0.8282\n",
      "Epoch 3/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5042 - accuracy: 0.8145 - val_loss: 0.4844 - val_accuracy: 0.8284\n",
      "Epoch 4/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 6.5987 - accuracy: 0.5170 - val_loss: 2.8321 - val_accuracy: 0.6392\n",
      "Epoch 5/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.5729 - accuracy: 0.7202 - val_loss: 0.8957 - val_accuracy: 0.7678\n",
      "Epoch 6/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.7227 - accuracy: 0.7648 - val_loss: 0.6288 - val_accuracy: 0.7781\n",
      "Epoch 7/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5780 - accuracy: 0.7907 - val_loss: 0.5044 - val_accuracy: 0.8047\n",
      "Epoch 8/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5154 - accuracy: 0.8053 - val_loss: 0.4721 - val_accuracy: 0.8202\n",
      "Epoch 9/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.5083 - accuracy: 0.8162 - val_loss: 0.4877 - val_accuracy: 0.8265\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5824 - accuracy: 0.7901 - val_loss: 0.5967 - val_accuracy: 0.7613\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5283 - accuracy: 0.7927 - val_loss: 0.4979 - val_accuracy: 0.8100\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4988 - accuracy: 0.8023 - val_loss: 0.4877 - val_accuracy: 0.8188\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4772 - accuracy: 0.8199 - val_loss: 0.4667 - val_accuracy: 0.8317\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4907 - accuracy: 0.8136 - val_loss: 0.5713 - val_accuracy: 0.7916\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.5285 - accuracy: 0.8045 - val_loss: 0.4614 - val_accuracy: 0.8413\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4765 - accuracy: 0.8256 - val_loss: 0.4827 - val_accuracy: 0.8186\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 0.4659 - accuracy: 0.8271 - val_loss: 0.4791 - val_accuracy: 0.8484\n",
      "Epoch 18/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.6394 - accuracy: 0.7874 - val_loss: 0.5200 - val_accuracy: 0.8439\n",
      "Epoch 19/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5319 - accuracy: 0.8017 - val_loss: 0.4696 - val_accuracy: 0.8286\n",
      "Epoch 20/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4799 - accuracy: 0.8249 - val_loss: 0.4668 - val_accuracy: 0.8482\n",
      "Epoch 21/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5735 - accuracy: 0.8179 - val_loss: 0.7612 - val_accuracy: 0.8032\n",
      "Epoch 22/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5148 - accuracy: 0.8114 - val_loss: 0.4560 - val_accuracy: 0.8233\n",
      "Epoch 23/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4913 - accuracy: 0.8259 - val_loss: 1.1701 - val_accuracy: 0.7329\n",
      "Epoch 24/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4969 - accuracy: 0.8193 - val_loss: 0.4805 - val_accuracy: 0.8484\n",
      "Epoch 25/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4989 - accuracy: 0.8167 - val_loss: 0.4483 - val_accuracy: 0.8178\n",
      "Epoch 26/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4554 - accuracy: 0.8304 - val_loss: 0.4432 - val_accuracy: 0.8413\n",
      "Epoch 27/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4597 - accuracy: 0.8285 - val_loss: 0.5065 - val_accuracy: 0.8531\n",
      "Epoch 28/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.6114 - accuracy: 0.8086 - val_loss: 0.6800 - val_accuracy: 0.7850\n",
      "Epoch 29/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5275 - accuracy: 0.8091 - val_loss: 0.4756 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.8422 - accuracy: 0.7658 - val_loss: 0.6216 - val_accuracy: 0.7973\n",
      "Epoch 31/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5735 - accuracy: 0.7924 - val_loss: 3.3177 - val_accuracy: 0.4377\n",
      "Epoch 32/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.6240 - accuracy: 0.7458 - val_loss: 0.5056 - val_accuracy: 0.8130\n",
      "Epoch 33/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4868 - accuracy: 0.8206 - val_loss: 0.4900 - val_accuracy: 0.8296\n",
      "Epoch 34/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1758 - accuracy: 0.7034 - val_loss: 0.7613 - val_accuracy: 0.7235\n",
      "Epoch 35/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5764 - accuracy: 0.7793 - val_loss: 0.5198 - val_accuracy: 0.7820\n",
      "Epoch 36/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4866 - accuracy: 0.8104 - val_loss: 0.4653 - val_accuracy: 0.8163\n",
      "Epoch 37/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 1.5901 - accuracy: 0.7109 - val_loss: 0.9696 - val_accuracy: 0.6650\n",
      "Epoch 38/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.7839 - accuracy: 0.7235 - val_loss: 0.6229 - val_accuracy: 0.7652\n",
      "Epoch 39/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5670 - accuracy: 0.7684 - val_loss: 0.6017 - val_accuracy: 0.8108\n",
      "Epoch 40/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5152 - accuracy: 0.7959 - val_loss: 0.5303 - val_accuracy: 0.8167\n",
      "Epoch 41/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4845 - accuracy: 0.8129 - val_loss: 0.5013 - val_accuracy: 0.7910\n",
      "Epoch 42/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4794 - accuracy: 0.8129 - val_loss: 0.4981 - val_accuracy: 0.8229\n",
      "Epoch 43/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5762 - accuracy: 0.7878 - val_loss: 0.5428 - val_accuracy: 0.8161\n",
      "Epoch 44/50\n",
      "612/612 [==============================] - 2s 4ms/step - loss: 0.6663 - accuracy: 0.7772 - val_loss: 0.5465 - val_accuracy: 0.8282\n",
      "Epoch 45/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.4934 - accuracy: 0.8222 - val_loss: 0.4829 - val_accuracy: 0.8315\n",
      "Epoch 46/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 1.1215 - accuracy: 0.7904 - val_loss: 8.6061 - val_accuracy: 0.4355\n",
      "Epoch 47/50\n",
      "612/612 [==============================] - 3s 5ms/step - loss: 8.5822 - accuracy: 0.4371 - val_loss: 8.6058 - val_accuracy: 0.4357\n",
      "Epoch 48/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 8.5794 - accuracy: 0.4372 - val_loss: 8.6025 - val_accuracy: 0.4359\n",
      "Epoch 49/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 4.4718 - accuracy: 0.6093 - val_loss: 1.0833 - val_accuracy: 0.7881\n",
      "Epoch 50/50\n",
      "612/612 [==============================] - 3s 4ms/step - loss: 0.5965 - accuracy: 0.8027 - val_loss: 0.5432 - val_accuracy: 0.8227\n",
      "153/153 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.8227\n",
      "Test accuracy: 0.8226631283760071\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000c1287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.8226631212926979\n",
      "Precision: 0.8368983957219251\n",
      "Recall: 0.7357780912082745\n",
      "F1 Score: 0.7830873154866149\n",
      "ROC AUC: 0.8126754322804588\n",
      "Specificity: 0.8895727733526431\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Specificity: {specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f75530e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.6692 - accuracy: 0.7269 - val_loss: 0.5471 - val_accuracy: 0.8056\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.5643 - accuracy: 0.7789 - val_loss: 0.5868 - val_accuracy: 0.8017\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5483 - accuracy: 0.7941 - val_loss: 0.5159 - val_accuracy: 0.8170\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5100 - accuracy: 0.8086 - val_loss: 0.5460 - val_accuracy: 0.8369\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.6308 - accuracy: 0.7848 - val_loss: 0.7256 - val_accuracy: 0.7512\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5577 - accuracy: 0.7905 - val_loss: 0.5183 - val_accuracy: 0.8260\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5110 - accuracy: 0.8070 - val_loss: 0.4939 - val_accuracy: 0.8251\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4800 - accuracy: 0.8084 - val_loss: 0.4689 - val_accuracy: 0.8233\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4705 - accuracy: 0.8169 - val_loss: 0.5498 - val_accuracy: 0.7215\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4524 - accuracy: 0.8238 - val_loss: 0.4754 - val_accuracy: 0.8235\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4593 - accuracy: 0.8296 - val_loss: 0.4645 - val_accuracy: 0.8325\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4386 - accuracy: 0.8334 - val_loss: 0.4557 - val_accuracy: 0.8201\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4667 - accuracy: 0.8311 - val_loss: 0.4691 - val_accuracy: 0.8156\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4574 - accuracy: 0.8266 - val_loss: 0.4578 - val_accuracy: 0.8319\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5463 - accuracy: 0.8125 - val_loss: 0.5503 - val_accuracy: 0.7855\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.5365 - accuracy: 0.8011 - val_loss: 0.6729 - val_accuracy: 0.6609\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4890 - accuracy: 0.8048 - val_loss: 0.4917 - val_accuracy: 0.8278\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4582 - accuracy: 0.8281 - val_loss: 0.6922 - val_accuracy: 0.6814\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4553 - accuracy: 0.8281 - val_loss: 0.4914 - val_accuracy: 0.8436\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4495 - accuracy: 0.8346 - val_loss: 0.4965 - val_accuracy: 0.8432\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4391 - accuracy: 0.8383 - val_loss: 0.5066 - val_accuracy: 0.8432\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4361 - accuracy: 0.8328 - val_loss: 0.5585 - val_accuracy: 0.7729\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4489 - accuracy: 0.8297 - val_loss: 0.5079 - val_accuracy: 0.8485\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.8744 - accuracy: 0.7904 - val_loss: 1.7973 - val_accuracy: 0.7017\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.8368 - accuracy: 0.7589 - val_loss: 0.5860 - val_accuracy: 0.7903\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.5218 - accuracy: 0.8111 - val_loss: 0.5320 - val_accuracy: 0.8200\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4799 - accuracy: 0.8211 - val_loss: 0.5897 - val_accuracy: 0.8420\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 1.3965 - accuracy: 0.7363 - val_loss: 3.0225 - val_accuracy: 0.6027\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.8036 - accuracy: 0.7510 - val_loss: 0.5696 - val_accuracy: 0.7912\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.5288 - accuracy: 0.7904 - val_loss: 0.5585 - val_accuracy: 0.8120\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4804 - accuracy: 0.8138 - val_loss: 0.5555 - val_accuracy: 0.8246\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4740 - accuracy: 0.8251 - val_loss: 0.5389 - val_accuracy: 0.8302\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4767 - accuracy: 0.8119 - val_loss: 0.5206 - val_accuracy: 0.8343\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4681 - accuracy: 0.8143 - val_loss: 0.5040 - val_accuracy: 0.8283\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4419 - accuracy: 0.8322 - val_loss: 0.4779 - val_accuracy: 0.8184\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4460 - accuracy: 0.8137 - val_loss: 0.4820 - val_accuracy: 0.8301\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4361 - accuracy: 0.8363 - val_loss: 0.5449 - val_accuracy: 0.8427\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4322 - accuracy: 0.8398 - val_loss: 0.4836 - val_accuracy: 0.7961\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 1.0092 - accuracy: 0.7309 - val_loss: 0.6260 - val_accuracy: 0.7842\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.6098 - accuracy: 0.7734 - val_loss: 0.5435 - val_accuracy: 0.7886\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5243 - accuracy: 0.8035 - val_loss: 0.5419 - val_accuracy: 0.7845\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5238 - accuracy: 0.8032 - val_loss: 1.2328 - val_accuracy: 0.5441\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5566 - accuracy: 0.7979 - val_loss: 0.5161 - val_accuracy: 0.8138\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.7821 - accuracy: 0.7719 - val_loss: 1.3962 - val_accuracy: 0.7455\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.6556 - accuracy: 0.7881 - val_loss: 0.5075 - val_accuracy: 0.8180\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4629 - accuracy: 0.8161 - val_loss: 0.4908 - val_accuracy: 0.8212\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4637 - accuracy: 0.8219 - val_loss: 0.4770 - val_accuracy: 0.8204\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4443 - accuracy: 0.8249 - val_loss: 0.4869 - val_accuracy: 0.8310\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5005 - accuracy: 0.8087 - val_loss: 0.6115 - val_accuracy: 0.7836\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4561 - accuracy: 0.8206 - val_loss: 0.5252 - val_accuracy: 0.7351\n",
      "382/382 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 4s 10ms/step - loss: 0.6712 - accuracy: 0.7185 - val_loss: 2.1695 - val_accuracy: 0.5698\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5758 - accuracy: 0.7774 - val_loss: 0.5126 - val_accuracy: 0.7964\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.5017 - accuracy: 0.8066 - val_loss: 0.5303 - val_accuracy: 0.8109\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.7994 - accuracy: 0.7525 - val_loss: 0.5376 - val_accuracy: 0.7692\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5147 - accuracy: 0.8014 - val_loss: 0.5550 - val_accuracy: 0.8135\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5133 - accuracy: 0.7995 - val_loss: 0.4795 - val_accuracy: 0.8117\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.9191 - accuracy: 0.7683 - val_loss: 0.5769 - val_accuracy: 0.7828\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5359 - accuracy: 0.8084 - val_loss: 0.4989 - val_accuracy: 0.8098\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4818 - accuracy: 0.8208 - val_loss: 0.5011 - val_accuracy: 0.8026\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.6828 - accuracy: 0.7742 - val_loss: 0.5939 - val_accuracy: 0.7490\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4835 - accuracy: 0.8137 - val_loss: 0.4986 - val_accuracy: 0.8203\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4742 - accuracy: 0.8189 - val_loss: 0.5242 - val_accuracy: 0.7680\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4731 - accuracy: 0.8240 - val_loss: 0.4864 - val_accuracy: 0.8214\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4657 - accuracy: 0.8272 - val_loss: 0.4803 - val_accuracy: 0.7961\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4557 - accuracy: 0.8323 - val_loss: 0.4798 - val_accuracy: 0.8326\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4539 - accuracy: 0.8336 - val_loss: 0.4849 - val_accuracy: 0.8134\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5474 - accuracy: 0.8016 - val_loss: 0.5694 - val_accuracy: 0.7112\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.7751 - val_loss: 0.5839 - val_accuracy: 0.8083\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.5334 - accuracy: 0.8187 - val_loss: 0.5296 - val_accuracy: 0.8036\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.6738 - accuracy: 0.7629 - val_loss: 0.5207 - val_accuracy: 0.7925\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4838 - accuracy: 0.8122 - val_loss: 0.5148 - val_accuracy: 0.8155\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.6012 - accuracy: 0.7820 - val_loss: 0.5318 - val_accuracy: 0.7948\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4870 - accuracy: 0.8150 - val_loss: 0.4863 - val_accuracy: 0.8115\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4705 - accuracy: 0.8273 - val_loss: 0.4827 - val_accuracy: 0.8210\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4905 - accuracy: 0.8187 - val_loss: 0.4911 - val_accuracy: 0.8119\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 4s 10ms/step - loss: 0.4601 - accuracy: 0.8293 - val_loss: 0.4843 - val_accuracy: 0.8184\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4525 - accuracy: 0.8253 - val_loss: 0.5124 - val_accuracy: 0.7726\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 4s 10ms/step - loss: 0.4532 - accuracy: 0.8287 - val_loss: 0.5105 - val_accuracy: 0.7772\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4452 - accuracy: 0.8341 - val_loss: 0.4944 - val_accuracy: 0.8199\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4361 - accuracy: 0.8349 - val_loss: 0.5035 - val_accuracy: 0.8314\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4408 - accuracy: 0.8282 - val_loss: 0.4750 - val_accuracy: 0.8191\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4531 - accuracy: 0.8360 - val_loss: 0.4930 - val_accuracy: 0.8251\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4708 - accuracy: 0.8224 - val_loss: 0.4948 - val_accuracy: 0.8287\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.6606 - accuracy: 0.7931 - val_loss: 0.5783 - val_accuracy: 0.8090\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4823 - accuracy: 0.8158 - val_loss: 0.5035 - val_accuracy: 0.8152\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4629 - accuracy: 0.8145 - val_loss: 0.5114 - val_accuracy: 0.7936\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 3s 8ms/step - loss: 0.4439 - accuracy: 0.8372 - val_loss: 0.4911 - val_accuracy: 0.8209\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4465 - accuracy: 0.8301 - val_loss: 0.4996 - val_accuracy: 0.8304\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4278 - accuracy: 0.8414 - val_loss: 0.4828 - val_accuracy: 0.8151\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4287 - accuracy: 0.8423 - val_loss: 0.5253 - val_accuracy: 0.8330\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4667 - accuracy: 0.8164 - val_loss: 0.5392 - val_accuracy: 0.8358\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4203 - accuracy: 0.8389 - val_loss: 0.5034 - val_accuracy: 0.8392\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4451 - accuracy: 0.8368 - val_loss: 0.4948 - val_accuracy: 0.8336\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4237 - accuracy: 0.8468 - val_loss: 0.5021 - val_accuracy: 0.8271\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5755 - accuracy: 0.7967 - val_loss: 0.5635 - val_accuracy: 0.8036\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4482 - accuracy: 0.8216 - val_loss: 0.4757 - val_accuracy: 0.8235\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5095 - accuracy: 0.8005 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.5568 - accuracy: 0.7959 - val_loss: 0.5272 - val_accuracy: 0.8114\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 4s 9ms/step - loss: 0.4529 - accuracy: 0.8215 - val_loss: 0.4753 - val_accuracy: 0.8246\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 3s 9ms/step - loss: 0.4689 - accuracy: 0.8165 - val_loss: 0.4714 - val_accuracy: 0.8309\n",
      "382/382 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.7829964814663285\n",
      "Precision: 0.7624877840378095\n",
      "Recall: 0.7766324371374429\n",
      "F1 Score: 0.7605055415607089\n",
      "ROC AUC: 0.7822925083897085\n",
      "Specificity: 0.7879525796419742\n"
     ]
    }
   ],
   "source": [
    "# 2 Layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Reshape the data for use in a CNN model\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Define the k-fold cross-validation generator\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "acc_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "spec_scores = []\n",
    "\n",
    "# Loop through the cross-validation splits\n",
    "for train, test in kfold.split(X):\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Append the evaluation metrics to the lists\n",
    "    acc_scores.append(accuracy)\n",
    "    prec_scores.append(precision)\n",
    "    rec_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(auc)\n",
    "    spec_scores.append(specificity)\n",
    "\n",
    "# Compute the mean of the evaluation metrics\n",
    "mean_acc = np.mean(acc_scores)\n",
    "mean_prec = np.mean(prec_scores)\n",
    "mean_rec = np.mean(rec_scores)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "mean_auc = np.mean(auc_scores)\n",
    "mean_spec = np.mean(spec_scores)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", mean_acc)\n",
    "print(\"Precision:\", mean_prec)\n",
    "print(\"Recall:\", mean_rec)\n",
    "print(\"F1 Score:\", mean_f1)\n",
    "print(\"ROC AUC:\", mean_auc)\n",
    "print(\"Specificity:\", mean_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41342e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13f811d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Layers\n",
    "# Reshape the data for use in a CNN model\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89cbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), \n",
    "                                                                    tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), \n",
    "                                                                    tf.keras.metrics.TrueNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ecb4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "382/382 [==============================] - 6s 13ms/step - loss: 0.5198 - accuracy: 0.7645 - precision: 0.7629 - recall: 0.6679 - auc: 0.8197 - true_negatives: 5781.0000 - val_loss: 0.4562 - val_accuracy: 0.8165 - val_precision: 0.8459 - val_recall: 0.7087 - val_auc: 0.8546 - val_true_negatives: 6197.0000\n",
      "Epoch 2/30\n",
      "382/382 [==============================] - 4s 12ms/step - loss: 0.4287 - accuracy: 0.8267 - precision: 0.8441 - recall: 0.7394 - auc: 0.8676 - true_negatives: 6160.0000 - val_loss: 0.4290 - val_accuracy: 0.8296 - val_precision: 0.8549 - val_recall: 0.7342 - val_auc: 0.8665 - val_true_negatives: 6221.0000\n",
      "Epoch 3/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.4043 - accuracy: 0.8382 - precision: 0.8627 - recall: 0.7484 - auc: 0.8771 - true_negatives: 6253.0000 - val_loss: 0.4182 - val_accuracy: 0.8413 - val_precision: 0.8950 - val_recall: 0.7209 - val_auc: 0.8702 - val_true_negatives: 6435.0000\n",
      "Epoch 4/30\n",
      "382/382 [==============================] - 5s 13ms/step - loss: 0.3866 - accuracy: 0.8478 - precision: 0.8769 - recall: 0.7575 - auc: 0.8847 - true_negatives: 6321.0000 - val_loss: 0.4064 - val_accuracy: 0.8381 - val_precision: 0.8612 - val_recall: 0.7500 - val_auc: 0.8729 - val_true_negatives: 6241.0000\n",
      "Epoch 5/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3820 - accuracy: 0.8494 - precision: 0.8824 - recall: 0.7555 - auc: 0.8878 - true_negatives: 6351.0000 - val_loss: 0.3996 - val_accuracy: 0.8413 - val_precision: 0.8780 - val_recall: 0.7393 - val_auc: 0.8757 - val_true_negatives: 6338.0000\n",
      "Epoch 6/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3687 - accuracy: 0.8548 - precision: 0.8869 - recall: 0.7647 - auc: 0.8930 - true_negatives: 6368.0000 - val_loss: 0.4006 - val_accuracy: 0.8396 - val_precision: 0.8664 - val_recall: 0.7479 - val_auc: 0.8734 - val_true_negatives: 6271.0000\n",
      "Epoch 7/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3602 - accuracy: 0.8592 - precision: 0.8969 - recall: 0.7652 - auc: 0.8970 - true_negatives: 6419.0000 - val_loss: 0.4146 - val_accuracy: 0.8241 - val_precision: 0.8218 - val_recall: 0.7623 - val_auc: 0.8697 - val_true_negatives: 6004.0000\n",
      "Epoch 8/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3543 - accuracy: 0.8615 - precision: 0.8998 - recall: 0.7680 - auc: 0.9008 - true_negatives: 6432.0000 - val_loss: 0.4088 - val_accuracy: 0.8552 - val_precision: 0.9366 - val_recall: 0.7170 - val_auc: 0.8773 - val_true_negatives: 6627.0000\n",
      "Epoch 9/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3473 - accuracy: 0.8605 - precision: 0.8980 - recall: 0.7675 - auc: 0.9049 - true_negatives: 6423.0000 - val_loss: 0.3885 - val_accuracy: 0.8495 - val_precision: 0.8978 - val_recall: 0.7395 - val_auc: 0.8791 - val_true_negatives: 6437.0000\n",
      "Epoch 10/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3391 - accuracy: 0.8651 - precision: 0.9006 - recall: 0.7765 - auc: 0.9078 - true_negatives: 6431.0000 - val_loss: 0.3967 - val_accuracy: 0.8342 - val_precision: 0.8343 - val_recall: 0.7739 - val_auc: 0.8768 - val_true_negatives: 6066.0000\n",
      "Epoch 11/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3341 - accuracy: 0.8685 - precision: 0.9057 - recall: 0.7799 - auc: 0.9121 - true_negatives: 6455.0000 - val_loss: 0.3983 - val_accuracy: 0.8456 - val_precision: 0.8886 - val_recall: 0.7389 - val_auc: 0.8773 - val_true_negatives: 6392.0000\n",
      "Epoch 12/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3285 - accuracy: 0.8712 - precision: 0.9103 - recall: 0.7819 - auc: 0.9148 - true_negatives: 6477.0000 - val_loss: 0.4026 - val_accuracy: 0.8360 - val_precision: 0.8418 - val_recall: 0.7689 - val_auc: 0.8760 - val_true_negatives: 6115.0000\n",
      "Epoch 13/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3234 - accuracy: 0.8736 - precision: 0.9135 - recall: 0.7845 - auc: 0.9180 - true_negatives: 6492.0000 - val_loss: 0.4130 - val_accuracy: 0.8243 - val_precision: 0.8029 - val_recall: 0.7919 - val_auc: 0.8791 - val_true_negatives: 5849.0000\n",
      "Epoch 14/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3161 - accuracy: 0.8742 - precision: 0.9101 - recall: 0.7898 - auc: 0.9231 - true_negatives: 6472.0000 - val_loss: 0.4123 - val_accuracy: 0.8225 - val_precision: 0.8022 - val_recall: 0.7876 - val_auc: 0.8793 - val_true_negatives: 5850.0000\n",
      "Epoch 15/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3088 - accuracy: 0.8750 - precision: 0.9130 - recall: 0.7887 - auc: 0.9254 - true_negatives: 6487.0000 - val_loss: 0.3965 - val_accuracy: 0.8404 - val_precision: 0.8577 - val_recall: 0.7606 - val_auc: 0.8787 - val_true_negatives: 6213.0000\n",
      "Epoch 16/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.3012 - accuracy: 0.8789 - precision: 0.9174 - recall: 0.7939 - auc: 0.9292 - true_negatives: 6507.0000 - val_loss: 0.4112 - val_accuracy: 0.8287 - val_precision: 0.8284 - val_recall: 0.7663 - val_auc: 0.8757 - val_true_negatives: 6039.0000\n",
      "Epoch 17/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.3007 - accuracy: 0.8810 - precision: 0.9161 - recall: 0.8007 - auc: 0.9302 - true_negatives: 6497.0000 - val_loss: 0.4180 - val_accuracy: 0.8406 - val_precision: 0.8670 - val_recall: 0.7500 - val_auc: 0.8717 - val_true_negatives: 6272.0000\n",
      "Epoch 18/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.2915 - accuracy: 0.8841 - precision: 0.9209 - recall: 0.8035 - auc: 0.9353 - true_negatives: 6520.0000 - val_loss: 0.4175 - val_accuracy: 0.8406 - val_precision: 0.8646 - val_recall: 0.7528 - val_auc: 0.8712 - val_true_negatives: 6257.0000\n",
      "Epoch 19/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.2817 - accuracy: 0.8851 - precision: 0.9200 - recall: 0.8069 - auc: 0.9394 - true_negatives: 6514.0000 - val_loss: 0.4352 - val_accuracy: 0.8449 - val_precision: 0.8996 - val_recall: 0.7258 - val_auc: 0.8692 - val_true_negatives: 6454.0000\n",
      "Epoch 20/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.2759 - accuracy: 0.8897 - precision: 0.9208 - recall: 0.8176 - auc: 0.9420 - true_negatives: 6513.0000 - val_loss: 0.4400 - val_accuracy: 0.8508 - val_precision: 0.9091 - val_recall: 0.7314 - val_auc: 0.8753 - val_true_negatives: 6496.0000\n",
      "Epoch 21/30\n",
      "382/382 [==============================] - 4s 12ms/step - loss: 0.2773 - accuracy: 0.8914 - precision: 0.9235 - recall: 0.8191 - auc: 0.9428 - true_negatives: 6526.0000 - val_loss: 0.4454 - val_accuracy: 0.8413 - val_precision: 0.8777 - val_recall: 0.7396 - val_auc: 0.8697 - val_true_negatives: 6336.0000\n",
      "Epoch 22/30\n",
      "382/382 [==============================] - 4s 12ms/step - loss: 0.2679 - accuracy: 0.8931 - precision: 0.9256 - recall: 0.8209 - auc: 0.9454 - true_negatives: 6536.0000 - val_loss: 0.4459 - val_accuracy: 0.8165 - val_precision: 0.7993 - val_recall: 0.7739 - val_auc: 0.8753 - val_true_negatives: 5849.0000\n",
      "Epoch 23/30\n",
      "382/382 [==============================] - 4s 12ms/step - loss: 0.2562 - accuracy: 0.8991 - precision: 0.9316 - recall: 0.8297 - auc: 0.9507 - true_negatives: 6563.0000 - val_loss: 0.4469 - val_accuracy: 0.8473 - val_precision: 0.9007 - val_recall: 0.7308 - val_auc: 0.8727 - val_true_negatives: 6456.0000\n",
      "Epoch 24/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.2520 - accuracy: 0.8981 - precision: 0.9282 - recall: 0.8309 - auc: 0.9521 - true_negatives: 6545.0000 - val_loss: 0.4547 - val_accuracy: 0.8322 - val_precision: 0.8418 - val_recall: 0.7580 - val_auc: 0.8701 - val_true_negatives: 6126.0000\n",
      "Epoch 25/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.2549 - accuracy: 0.8971 - precision: 0.9255 - recall: 0.8311 - auc: 0.9529 - true_negatives: 6531.0000 - val_loss: 0.4546 - val_accuracy: 0.8289 - val_precision: 0.8293 - val_recall: 0.7657 - val_auc: 0.8721 - val_true_negatives: 6045.0000\n",
      "Epoch 26/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.2438 - accuracy: 0.9012 - precision: 0.9283 - recall: 0.8382 - auc: 0.9568 - true_negatives: 6543.0000 - val_loss: 0.4706 - val_accuracy: 0.8215 - val_precision: 0.8090 - val_recall: 0.7739 - val_auc: 0.8672 - val_true_negatives: 5911.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "382/382 [==============================] - 4s 11ms/step - loss: 0.2383 - accuracy: 0.9028 - precision: 0.9292 - recall: 0.8414 - auc: 0.9583 - true_negatives: 6546.0000 - val_loss: 0.4722 - val_accuracy: 0.8222 - val_precision: 0.8089 - val_recall: 0.7760 - val_auc: 0.8748 - val_true_negatives: 5908.0000\n",
      "Epoch 28/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.2321 - accuracy: 0.9078 - precision: 0.9349 - recall: 0.8477 - auc: 0.9606 - true_negatives: 6573.0000 - val_loss: 0.4699 - val_accuracy: 0.8357 - val_precision: 0.8516 - val_recall: 0.7552 - val_auc: 0.8721 - val_true_negatives: 6184.0000\n",
      "Epoch 29/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.2251 - accuracy: 0.9093 - precision: 0.9326 - recall: 0.8537 - auc: 0.9629 - true_negatives: 6559.0000 - val_loss: 0.4913 - val_accuracy: 0.8348 - val_precision: 0.8549 - val_recall: 0.7486 - val_auc: 0.8683 - val_true_negatives: 6208.0000\n",
      "Epoch 30/30\n",
      "382/382 [==============================] - 5s 12ms/step - loss: 0.2225 - accuracy: 0.9101 - precision: 0.9308 - recall: 0.8577 - auc: 0.9648 - true_negatives: 6548.0000 - val_loss: 0.4805 - val_accuracy: 0.8327 - val_precision: 0.8431 - val_recall: 0.7576 - val_auc: 0.8716 - val_true_negatives: 6134.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f043af8070>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a7955cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.8327 - precision: 0.8431 - recall: 0.7576 - auc: 0.8716 - true_negatives: 6134.0000\n",
      "Test loss: 0.48046520352363586\n",
      "Test accuracy: 0.8326650857925415\n",
      "Test precision: 0.843137264251709\n",
      "Test recall: 0.7576382160186768\n",
      "Test F1-score: 0.49123272469496004\n",
      "Test ROC AUC: 0.8716430068016052\n",
      "Test specificity: 6134.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy, precision, recall, auc, specificity = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Test precision: {precision}\")\n",
    "print(f\"Test recall: {recall}\")\n",
    "print(f\"Test F1-score: {2 * (precision * recall) / (precision + recall+1)}\")\n",
    "print(f\"Test ROC AUC: {auc}\")\n",
    "print(f\"Test specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e687bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "489/489 [==============================] - 13s 24ms/step - loss: 0.4805 - accuracy: 0.7869 - precision_2: 0.8065 - recall_2: 0.6731 - auc_2: 0.8353 - false_positives_1: 1102.0000 - val_loss: 0.4034 - val_accuracy: 0.8425 - val_precision_2: 0.9318 - val_recall_2: 0.6919 - val_auc_2: 0.8691 - val_false_positives_1: 87.0000\n",
      "Epoch 2/50\n",
      "489/489 [==============================] - 11s 23ms/step - loss: 0.4039 - accuracy: 0.8359 - precision_2: 0.8951 - recall_2: 0.7066 - auc_2: 0.8688 - false_positives_1: 565.0000 - val_loss: 0.3797 - val_accuracy: 0.8451 - val_precision_2: 0.8988 - val_recall_2: 0.7292 - val_auc_2: 0.8759 - val_false_positives_1: 141.0000\n",
      "Epoch 3/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3804 - accuracy: 0.8474 - precision_2: 0.9141 - recall_2: 0.7176 - auc_2: 0.8772 - false_positives_1: 460.0000 - val_loss: 0.3683 - val_accuracy: 0.8543 - val_precision_2: 0.9422 - val_recall_2: 0.7117 - val_auc_2: 0.8758 - val_false_positives_1: 75.0000\n",
      "Epoch 4/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3704 - accuracy: 0.8539 - precision_2: 0.9265 - recall_2: 0.7225 - auc_2: 0.8827 - false_positives_1: 391.0000 - val_loss: 0.3782 - val_accuracy: 0.8481 - val_precision_2: 0.9019 - val_recall_2: 0.7338 - val_auc_2: 0.8738 - val_false_positives_1: 137.0000\n",
      "Epoch 5/50\n",
      "489/489 [==============================] - 12s 24ms/step - loss: 0.3615 - accuracy: 0.8566 - precision_2: 0.9321 - recall_2: 0.7241 - auc_2: 0.8873 - false_positives_1: 360.0000 - val_loss: 0.3604 - val_accuracy: 0.8589 - val_precision_2: 0.9491 - val_recall_2: 0.7169 - val_auc_2: 0.8789 - val_false_positives_1: 66.0000\n",
      "Epoch 6/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3523 - accuracy: 0.8609 - precision_2: 0.9383 - recall_2: 0.7290 - auc_2: 0.8901 - false_positives_1: 327.0000 - val_loss: 0.3616 - val_accuracy: 0.8614 - val_precision_2: 0.9394 - val_recall_2: 0.7315 - val_auc_2: 0.8816 - val_false_positives_1: 81.0000\n",
      "Epoch 7/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3446 - accuracy: 0.8629 - precision_2: 0.9432 - recall_2: 0.7298 - auc_2: 0.8936 - false_positives_1: 300.0000 - val_loss: 0.3644 - val_accuracy: 0.8604 - val_precision_2: 0.9585 - val_recall_2: 0.7129 - val_auc_2: 0.8820 - val_false_positives_1: 53.0000\n",
      "Epoch 8/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3420 - accuracy: 0.8659 - precision_2: 0.9452 - recall_2: 0.7353 - auc_2: 0.8975 - false_positives_1: 291.0000 - val_loss: 0.3679 - val_accuracy: 0.8568 - val_precision_2: 0.9301 - val_recall_2: 0.7286 - val_auc_2: 0.8735 - val_false_positives_1: 94.0000\n",
      "Epoch 9/50\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.3377 - accuracy: 0.8666 - precision_2: 0.9485 - recall_2: 0.7340 - auc_2: 0.8992 - false_positives_1: 272.0000 - val_loss: 0.3667 - val_accuracy: 0.8627 - val_precision_2: 0.9497 - val_recall_2: 0.7257 - val_auc_2: 0.8798 - val_false_positives_1: 66.0000\n",
      "Epoch 10/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3303 - accuracy: 0.8693 - precision_2: 0.9486 - recall_2: 0.7406 - auc_2: 0.9033 - false_positives_1: 274.0000 - val_loss: 0.3610 - val_accuracy: 0.8599 - val_precision_2: 0.9520 - val_recall_2: 0.7169 - val_auc_2: 0.8747 - val_false_positives_1: 62.0000\n",
      "Epoch 11/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.3249 - accuracy: 0.8712 - precision_2: 0.9539 - recall_2: 0.7406 - auc_2: 0.9063 - false_positives_1: 244.0000 - val_loss: 0.3611 - val_accuracy: 0.8637 - val_precision_2: 0.9575 - val_recall_2: 0.7216 - val_auc_2: 0.8803 - val_false_positives_1: 55.0000\n",
      "Epoch 12/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.3181 - accuracy: 0.8723 - precision_2: 0.9517 - recall_2: 0.7450 - auc_2: 0.9097 - false_positives_1: 258.0000 - val_loss: 0.3577 - val_accuracy: 0.8663 - val_precision_2: 0.9599 - val_recall_2: 0.7257 - val_auc_2: 0.8813 - val_false_positives_1: 52.0000\n",
      "Epoch 13/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.3107 - accuracy: 0.8762 - precision_2: 0.9572 - recall_2: 0.7497 - auc_2: 0.9138 - false_positives_1: 229.0000 - val_loss: 0.3630 - val_accuracy: 0.8670 - val_precision_2: 0.9565 - val_recall_2: 0.7303 - val_auc_2: 0.8816 - val_false_positives_1: 57.0000\n",
      "Epoch 14/50\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.3076 - accuracy: 0.8785 - precision_2: 0.9602 - recall_2: 0.7528 - auc_2: 0.9168 - false_positives_1: 213.0000 - val_loss: 0.3946 - val_accuracy: 0.8558 - val_precision_2: 0.9086 - val_recall_2: 0.7467 - val_auc_2: 0.8800 - val_false_positives_1: 129.0000\n",
      "Epoch 15/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.3037 - accuracy: 0.8774 - precision_2: 0.9558 - recall_2: 0.7540 - auc_2: 0.9202 - false_positives_1: 238.0000 - val_loss: 0.3762 - val_accuracy: 0.8635 - val_precision_2: 0.9610 - val_recall_2: 0.7181 - val_auc_2: 0.8795 - val_false_positives_1: 50.0000\n",
      "Epoch 16/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2992 - accuracy: 0.8799 - precision_2: 0.9612 - recall_2: 0.7551 - auc_2: 0.9215 - false_positives_1: 208.0000 - val_loss: 0.3886 - val_accuracy: 0.8632 - val_precision_2: 0.9574 - val_recall_2: 0.7204 - val_auc_2: 0.8757 - val_false_positives_1: 55.0000\n",
      "Epoch 17/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2969 - accuracy: 0.8785 - precision_2: 0.9580 - recall_2: 0.7547 - auc_2: 0.9251 - false_positives_1: 226.0000 - val_loss: 0.3731 - val_accuracy: 0.8637 - val_precision_2: 0.9315 - val_recall_2: 0.7443 - val_auc_2: 0.8846 - val_false_positives_1: 94.0000\n",
      "Epoch 18/50\n",
      "489/489 [==============================] - 15s 30ms/step - loss: 0.2885 - accuracy: 0.8832 - precision_2: 0.9604 - recall_2: 0.7638 - auc_2: 0.9281 - false_positives_1: 215.0000 - val_loss: 0.4246 - val_accuracy: 0.8535 - val_precision_2: 0.8950 - val_recall_2: 0.7548 - val_auc_2: 0.8771 - val_false_positives_1: 152.0000\n",
      "Epoch 19/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2838 - accuracy: 0.8863 - precision_2: 0.9628 - recall_2: 0.7691 - auc_2: 0.9311 - false_positives_1: 203.0000 - val_loss: 0.3812 - val_accuracy: 0.8665 - val_precision_2: 0.9530 - val_recall_2: 0.7321 - val_auc_2: 0.8807 - val_false_positives_1: 62.0000\n",
      "Epoch 20/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2820 - accuracy: 0.8843 - precision_2: 0.9600 - recall_2: 0.7667 - auc_2: 0.9341 - false_positives_1: 218.0000 - val_loss: 0.3963 - val_accuracy: 0.8617 - val_precision_2: 0.9414 - val_recall_2: 0.7303 - val_auc_2: 0.8771 - val_false_positives_1: 78.0000\n",
      "Epoch 21/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2721 - accuracy: 0.8882 - precision_2: 0.9635 - recall_2: 0.7730 - auc_2: 0.9375 - false_positives_1: 200.0000 - val_loss: 0.4124 - val_accuracy: 0.8553 - val_precision_2: 0.9155 - val_recall_2: 0.7385 - val_auc_2: 0.8740 - val_false_positives_1: 117.0000\n",
      "Epoch 22/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2737 - accuracy: 0.8889 - precision_2: 0.9649 - recall_2: 0.7734 - auc_2: 0.9408 - false_positives_1: 192.0000 - val_loss: 0.4044 - val_accuracy: 0.8543 - val_precision_2: 0.9099 - val_recall_2: 0.7414 - val_auc_2: 0.8763 - val_false_positives_1: 126.0000\n",
      "Epoch 23/50\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.2647 - accuracy: 0.8909 - precision_2: 0.9636 - recall_2: 0.7793 - auc_2: 0.9435 - false_positives_1: 201.0000 - val_loss: 0.4271 - val_accuracy: 0.8599 - val_precision_2: 0.9452 - val_recall_2: 0.7228 - val_auc_2: 0.8731 - val_false_positives_1: 72.0000\n",
      "Epoch 24/50\n",
      "489/489 [==============================] - 14s 29ms/step - loss: 0.2655 - accuracy: 0.8921 - precision_2: 0.9647 - recall_2: 0.7814 - auc_2: 0.9425 - false_positives_1: 195.0000 - val_loss: 0.4112 - val_accuracy: 0.8555 - val_precision_2: 0.9103 - val_recall_2: 0.7443 - val_auc_2: 0.8814 - val_false_positives_1: 126.0000\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2579 - accuracy: 0.8934 - precision_2: 0.9622 - recall_2: 0.7866 - auc_2: 0.9465 - false_positives_1: 211.0000 - val_loss: 0.4183 - val_accuracy: 0.8640 - val_precision_2: 0.9499 - val_recall_2: 0.7286 - val_auc_2: 0.8775 - val_false_positives_1: 66.0000\n",
      "Epoch 26/50\n",
      "489/489 [==============================] - 15s 30ms/step - loss: 0.2502 - accuracy: 0.8952 - precision_2: 0.9637 - recall_2: 0.7894 - auc_2: 0.9510 - false_positives_1: 203.0000 - val_loss: 0.4218 - val_accuracy: 0.8624 - val_precision_2: 0.9588 - val_recall_2: 0.7175 - val_auc_2: 0.8764 - val_false_positives_1: 53.0000\n",
      "Epoch 27/50\n",
      "489/489 [==============================] - 14s 29ms/step - loss: 0.2451 - accuracy: 0.8966 - precision_2: 0.9633 - recall_2: 0.7932 - auc_2: 0.9528 - false_positives_1: 206.0000 - val_loss: 0.4599 - val_accuracy: 0.8637 - val_precision_2: 0.9485 - val_recall_2: 0.7292 - val_auc_2: 0.8728 - val_false_positives_1: 68.0000\n",
      "Epoch 28/50\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.2387 - accuracy: 0.8992 - precision_2: 0.9631 - recall_2: 0.7997 - auc_2: 0.9564 - false_positives_1: 209.0000 - val_loss: 0.4439 - val_accuracy: 0.8573 - val_precision_2: 0.9264 - val_recall_2: 0.7333 - val_auc_2: 0.8777 - val_false_positives_1: 100.0000\n",
      "Epoch 29/50\n",
      "489/489 [==============================] - 13s 27ms/step - loss: 0.2344 - accuracy: 0.9008 - precision_2: 0.9623 - recall_2: 0.8041 - auc_2: 0.9591 - false_positives_1: 215.0000 - val_loss: 0.4561 - val_accuracy: 0.8576 - val_precision_2: 0.9215 - val_recall_2: 0.7385 - val_auc_2: 0.8771 - val_false_positives_1: 108.0000\n",
      "Epoch 30/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2349 - accuracy: 0.9014 - precision_2: 0.9628 - recall_2: 0.8051 - auc_2: 0.9576 - false_positives_1: 212.0000 - val_loss: 0.4905 - val_accuracy: 0.8558 - val_precision_2: 0.9150 - val_recall_2: 0.7402 - val_auc_2: 0.8711 - val_false_positives_1: 118.0000\n",
      "Epoch 31/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2273 - accuracy: 0.9027 - precision_2: 0.9615 - recall_2: 0.8093 - auc_2: 0.9610 - false_positives_1: 221.0000 - val_loss: 0.4415 - val_accuracy: 0.8566 - val_precision_2: 0.9366 - val_recall_2: 0.7222 - val_auc_2: 0.8685 - val_false_positives_1: 84.0000\n",
      "Epoch 32/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.2217 - accuracy: 0.9039 - precision_2: 0.9618 - recall_2: 0.8120 - auc_2: 0.9632 - false_positives_1: 220.0000 - val_loss: 0.4900 - val_accuracy: 0.8530 - val_precision_2: 0.8999 - val_recall_2: 0.7484 - val_auc_2: 0.8718 - val_false_positives_1: 143.0000\n",
      "Epoch 33/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.2215 - accuracy: 0.9054 - precision_2: 0.9613 - recall_2: 0.8159 - auc_2: 0.9641 - false_positives_1: 224.0000 - val_loss: 0.4893 - val_accuracy: 0.8591 - val_precision_2: 0.9231 - val_recall_2: 0.7408 - val_auc_2: 0.8731 - val_false_positives_1: 106.0000\n",
      "Epoch 34/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2120 - accuracy: 0.9089 - precision_2: 0.9639 - recall_2: 0.8220 - auc_2: 0.9669 - false_positives_1: 210.0000 - val_loss: 0.4864 - val_accuracy: 0.8543 - val_precision_2: 0.9013 - val_recall_2: 0.7501 - val_auc_2: 0.8733 - val_false_positives_1: 141.0000\n",
      "Epoch 35/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.2129 - accuracy: 0.9092 - precision_2: 0.9638 - recall_2: 0.8228 - auc_2: 0.9683 - false_positives_1: 211.0000 - val_loss: 0.5047 - val_accuracy: 0.8509 - val_precision_2: 0.9044 - val_recall_2: 0.7385 - val_auc_2: 0.8699 - val_false_positives_1: 134.0000\n",
      "Epoch 36/50\n",
      "489/489 [==============================] - 14s 28ms/step - loss: 0.2084 - accuracy: 0.9111 - precision_2: 0.9672 - recall_2: 0.8243 - auc_2: 0.9677 - false_positives_1: 191.0000 - val_loss: 0.5207 - val_accuracy: 0.8560 - val_precision_2: 0.9092 - val_recall_2: 0.7467 - val_auc_2: 0.8704 - val_false_positives_1: 128.0000\n",
      "Epoch 37/50\n",
      "489/489 [==============================] - 16s 32ms/step - loss: 0.2035 - accuracy: 0.9116 - precision_2: 0.9609 - recall_2: 0.8313 - auc_2: 0.9702 - false_positives_1: 231.0000 - val_loss: 0.5210 - val_accuracy: 0.8578 - val_precision_2: 0.9240 - val_recall_2: 0.7368 - val_auc_2: 0.8708 - val_false_positives_1: 104.0000\n",
      "Epoch 38/50\n",
      "489/489 [==============================] - 16s 32ms/step - loss: 0.1950 - accuracy: 0.9162 - precision_2: 0.9649 - recall_2: 0.8384 - auc_2: 0.9724 - false_positives_1: 208.0000 - val_loss: 0.5528 - val_accuracy: 0.8502 - val_precision_2: 0.8963 - val_recall_2: 0.7449 - val_auc_2: 0.8721 - val_false_positives_1: 148.0000\n",
      "Epoch 39/50\n",
      "489/489 [==============================] - 15s 30ms/step - loss: 0.1993 - accuracy: 0.9152 - precision_2: 0.9625 - recall_2: 0.8384 - auc_2: 0.9715 - false_positives_1: 223.0000 - val_loss: 0.5284 - val_accuracy: 0.8558 - val_precision_2: 0.9121 - val_recall_2: 0.7432 - val_auc_2: 0.8723 - val_false_positives_1: 123.0000\n",
      "Epoch 40/50\n",
      "489/489 [==============================] - 14s 30ms/step - loss: 0.2013 - accuracy: 0.9139 - precision_2: 0.9627 - recall_2: 0.8351 - auc_2: 0.9711 - false_positives_1: 221.0000 - val_loss: 0.4995 - val_accuracy: 0.8583 - val_precision_2: 0.9254 - val_recall_2: 0.7368 - val_auc_2: 0.8746 - val_false_positives_1: 102.0000\n",
      "Epoch 41/50\n",
      "489/489 [==============================] - 14s 29ms/step - loss: 0.1896 - accuracy: 0.9177 - precision_2: 0.9652 - recall_2: 0.8417 - auc_2: 0.9747 - false_positives_1: 207.0000 - val_loss: 0.5768 - val_accuracy: 0.8558 - val_precision_2: 0.9248 - val_recall_2: 0.7309 - val_auc_2: 0.8697 - val_false_positives_1: 102.0000\n",
      "Epoch 42/50\n",
      "489/489 [==============================] - 15s 30ms/step - loss: 0.1868 - accuracy: 0.9198 - precision_2: 0.9620 - recall_2: 0.8498 - auc_2: 0.9750 - false_positives_1: 229.0000 - val_loss: 0.5637 - val_accuracy: 0.8497 - val_precision_2: 0.8864 - val_recall_2: 0.7542 - val_auc_2: 0.8725 - val_false_positives_1: 166.0000\n",
      "Epoch 43/50\n",
      "489/489 [==============================] - 15s 31ms/step - loss: 0.1873 - accuracy: 0.9221 - precision_2: 0.9672 - recall_2: 0.8504 - auc_2: 0.9764 - false_positives_1: 197.0000 - val_loss: 0.5622 - val_accuracy: 0.8527 - val_precision_2: 0.8954 - val_recall_2: 0.7525 - val_auc_2: 0.8716 - val_false_positives_1: 151.0000\n",
      "Epoch 44/50\n",
      "489/489 [==============================] - 13s 28ms/step - loss: 0.1784 - accuracy: 0.9219 - precision_2: 0.9645 - recall_2: 0.8524 - auc_2: 0.9781 - false_positives_1: 214.0000 - val_loss: 0.5396 - val_accuracy: 0.8540 - val_precision_2: 0.9001 - val_recall_2: 0.7507 - val_auc_2: 0.8741 - val_false_positives_1: 143.0000\n",
      "Epoch 45/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1792 - accuracy: 0.9228 - precision_2: 0.9649 - recall_2: 0.8542 - auc_2: 0.9781 - false_positives_1: 212.0000 - val_loss: 0.5939 - val_accuracy: 0.8461 - val_precision_2: 0.8729 - val_recall_2: 0.7600 - val_auc_2: 0.8734 - val_false_positives_1: 190.0000\n",
      "Epoch 46/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1806 - accuracy: 0.9226 - precision_2: 0.9624 - recall_2: 0.8559 - auc_2: 0.9771 - false_positives_1: 228.0000 - val_loss: 0.5412 - val_accuracy: 0.8527 - val_precision_2: 0.8970 - val_recall_2: 0.7507 - val_auc_2: 0.8729 - val_false_positives_1: 148.0000\n",
      "Epoch 47/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1699 - accuracy: 0.9244 - precision_2: 0.9660 - recall_2: 0.8570 - auc_2: 0.9799 - false_positives_1: 206.0000 - val_loss: 0.5829 - val_accuracy: 0.8527 - val_precision_2: 0.9078 - val_recall_2: 0.7397 - val_auc_2: 0.8723 - val_false_positives_1: 129.0000\n",
      "Epoch 48/50\n",
      "489/489 [==============================] - 13s 26ms/step - loss: 0.1613 - accuracy: 0.9287 - precision_2: 0.9645 - recall_2: 0.8684 - auc_2: 0.9817 - false_positives_1: 218.0000 - val_loss: 0.6077 - val_accuracy: 0.8422 - val_precision_2: 0.8726 - val_recall_2: 0.7501 - val_auc_2: 0.8712 - val_false_positives_1: 188.0000\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 12s 25ms/step - loss: 0.1678 - accuracy: 0.9256 - precision_2: 0.9621 - recall_2: 0.8634 - auc_2: 0.9803 - false_positives_1: 232.0000 - val_loss: 0.6208 - val_accuracy: 0.8494 - val_precision_2: 0.9046 - val_recall_2: 0.7344 - val_auc_2: 0.8748 - val_false_positives_1: 133.0000\n",
      "Epoch 50/50\n",
      "489/489 [==============================] - 12s 25ms/step - loss: 0.1706 - accuracy: 0.9241 - precision_2: 0.9623 - recall_2: 0.8598 - auc_2: 0.9798 - false_positives_1: 230.0000 - val_loss: 0.5656 - val_accuracy: 0.8550 - val_precision_2: 0.9049 - val_recall_2: 0.7484 - val_auc_2: 0.8782 - val_false_positives_1: 135.0000\n"
     ]
    }
   ],
   "source": [
    "#4 Layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for Conv1D input\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), tf.keras.metrics.FalsePositives()])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc21f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 2s 11ms/step\n",
      "Accuracy: 0.8574350582941297\n",
      "Precision: 0.9071753986332574\n",
      "Recall: 0.7489421720733427\n",
      "F1 Score: 0.8204996137007468\n",
      "ROC AUC: 0.8813840328155602\n",
      "Specificity: 0.940984793627806\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model on test set\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "precision = precision_score(y_test, y_pred.round())\n",
    "recall = recall_score(y_test, y_pred.round())\n",
    "f1 = f1_score(y_test, y_pred.round())\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred.round()).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a7ffd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "612/612 [==============================] - 28s 43ms/step - loss: 0.5249 - accuracy: 0.7596 - precision_8: 0.7539 - recall_8: 0.6676 - auc_8: 0.8096 - specificity_at_sensitivity_5: 0.9385 - val_loss: 0.4094 - val_accuracy: 0.8290 - val_precision_8: 0.8900 - val_recall_8: 0.6925 - val_auc_8: 0.8639 - val_specificity_at_sensitivity_5: 0.9938\n",
      "Epoch 2/50\n",
      "612/612 [==============================] - 26s 42ms/step - loss: 0.4433 - accuracy: 0.8124 - precision_8: 0.8441 - recall_8: 0.6997 - auc_8: 0.8501 - specificity_at_sensitivity_5: 0.9818 - val_loss: 0.3921 - val_accuracy: 0.8392 - val_precision_8: 0.8887 - val_recall_8: 0.7207 - val_auc_8: 0.8714 - val_specificity_at_sensitivity_5: 0.9949\n",
      "Epoch 3/50\n",
      "612/612 [==============================] - 26s 42ms/step - loss: 0.4340 - accuracy: 0.8186 - precision_8: 0.8605 - recall_8: 0.6979 - auc_8: 0.8523 - specificity_at_sensitivity_5: 0.9868 - val_loss: 0.3868 - val_accuracy: 0.8452 - val_precision_8: 0.8950 - val_recall_8: 0.7297 - val_auc_8: 0.8727 - val_specificity_at_sensitivity_5: 0.9971\n",
      "Epoch 4/50\n",
      "612/612 [==============================] - 26s 42ms/step - loss: 0.4235 - accuracy: 0.8253 - precision_8: 0.8723 - recall_8: 0.7030 - auc_8: 0.8562 - specificity_at_sensitivity_5: 0.9895 - val_loss: 0.3811 - val_accuracy: 0.8490 - val_precision_8: 0.8985 - val_recall_8: 0.7362 - val_auc_8: 0.8794 - val_specificity_at_sensitivity_5: 0.9960\n",
      "Epoch 5/50\n",
      "612/612 [==============================] - 26s 43ms/step - loss: 0.4141 - accuracy: 0.8298 - precision_8: 0.8782 - recall_8: 0.7086 - auc_8: 0.8624 - specificity_at_sensitivity_5: 0.9923 - val_loss: 0.3765 - val_accuracy: 0.8523 - val_precision_8: 0.9388 - val_recall_8: 0.7066 - val_auc_8: 0.8776 - val_specificity_at_sensitivity_5: 0.9971\n",
      "Epoch 6/50\n",
      "612/612 [==============================] - 26s 43ms/step - loss: 0.4181 - accuracy: 0.8272 - precision_8: 0.8725 - recall_8: 0.7078 - auc_8: 0.8602 - specificity_at_sensitivity_5: 0.9897 - val_loss: 0.3864 - val_accuracy: 0.8458 - val_precision_8: 0.9381 - val_recall_8: 0.6911 - val_auc_8: 0.8787 - val_specificity_at_sensitivity_5: 0.9967\n",
      "Epoch 7/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4162 - accuracy: 0.8281 - precision_8: 0.8748 - recall_8: 0.7078 - auc_8: 0.8608 - specificity_at_sensitivity_5: 0.9907 - val_loss: 0.3744 - val_accuracy: 0.8538 - val_precision_8: 0.9016 - val_recall_8: 0.7452 - val_auc_8: 0.8790 - val_specificity_at_sensitivity_5: 0.9964\n",
      "Epoch 8/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4042 - accuracy: 0.8311 - precision_8: 0.8793 - recall_8: 0.7108 - auc_8: 0.8683 - specificity_at_sensitivity_5: 0.9934 - val_loss: 0.3732 - val_accuracy: 0.8497 - val_precision_8: 0.8919 - val_recall_8: 0.7447 - val_auc_8: 0.8792 - val_specificity_at_sensitivity_5: 0.9967\n",
      "Epoch 9/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4079 - accuracy: 0.8325 - precision_8: 0.8825 - recall_8: 0.7113 - auc_8: 0.8649 - specificity_at_sensitivity_5: 0.9934 - val_loss: 0.3652 - val_accuracy: 0.8591 - val_precision_8: 0.9477 - val_recall_8: 0.7156 - val_auc_8: 0.8785 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4040 - accuracy: 0.8356 - precision_8: 0.8864 - recall_8: 0.7154 - auc_8: 0.8654 - specificity_at_sensitivity_5: 0.9935 - val_loss: 0.3643 - val_accuracy: 0.8597 - val_precision_8: 0.9478 - val_recall_8: 0.7170 - val_auc_8: 0.8808 - val_specificity_at_sensitivity_5: 0.9975\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4059 - accuracy: 0.8348 - precision_8: 0.8864 - recall_8: 0.7131 - auc_8: 0.8652 - specificity_at_sensitivity_5: 0.9924 - val_loss: 0.3671 - val_accuracy: 0.8546 - val_precision_8: 0.9121 - val_recall_8: 0.7367 - val_auc_8: 0.8792 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4011 - accuracy: 0.8370 - precision_8: 0.8885 - recall_8: 0.7167 - auc_8: 0.8659 - specificity_at_sensitivity_5: 0.9946 - val_loss: 0.3673 - val_accuracy: 0.8527 - val_precision_8: 0.9297 - val_recall_8: 0.7156 - val_auc_8: 0.8817 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.4009 - accuracy: 0.8388 - precision_8: 0.8920 - recall_8: 0.7178 - auc_8: 0.8663 - specificity_at_sensitivity_5: 0.9941 - val_loss: 0.3644 - val_accuracy: 0.8595 - val_precision_8: 0.9270 - val_recall_8: 0.7348 - val_auc_8: 0.8784 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 27s 45ms/step - loss: 0.4017 - accuracy: 0.8350 - precision_8: 0.8897 - recall_8: 0.7103 - auc_8: 0.8660 - specificity_at_sensitivity_5: 0.9957 - val_loss: 0.3788 - val_accuracy: 0.8505 - val_precision_8: 0.9120 - val_recall_8: 0.7264 - val_auc_8: 0.8767 - val_specificity_at_sensitivity_5: 0.9975\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 28s 45ms/step - loss: 0.3990 - accuracy: 0.8402 - precision_8: 0.8942 - recall_8: 0.7194 - auc_8: 0.8686 - specificity_at_sensitivity_5: 0.9941 - val_loss: 0.3973 - val_accuracy: 0.8445 - val_precision_8: 0.8622 - val_recall_8: 0.7649 - val_auc_8: 0.8765 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 27s 45ms/step - loss: 0.4017 - accuracy: 0.8379 - precision_8: 0.8845 - recall_8: 0.7235 - auc_8: 0.8682 - specificity_at_sensitivity_5: 0.9922 - val_loss: 0.3641 - val_accuracy: 0.8560 - val_precision_8: 0.9294 - val_recall_8: 0.7240 - val_auc_8: 0.8786 - val_specificity_at_sensitivity_5: 0.9989\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 28s 45ms/step - loss: 0.4055 - accuracy: 0.8358 - precision_8: 0.8892 - recall_8: 0.7129 - auc_8: 0.8638 - specificity_at_sensitivity_5: 0.9929 - val_loss: 0.3650 - val_accuracy: 0.8566 - val_precision_8: 0.9079 - val_recall_8: 0.7461 - val_auc_8: 0.8777 - val_specificity_at_sensitivity_5: 0.9975\n",
      "Epoch 18/50\n",
      "612/612 [==============================] - 29s 47ms/step - loss: 0.3972 - accuracy: 0.8386 - precision_8: 0.8878 - recall_8: 0.7218 - auc_8: 0.8696 - specificity_at_sensitivity_5: 0.9945 - val_loss: 0.3657 - val_accuracy: 0.8519 - val_precision_8: 0.8952 - val_recall_8: 0.7471 - val_auc_8: 0.8819 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 19/50\n",
      "612/612 [==============================] - 29s 47ms/step - loss: 0.3977 - accuracy: 0.8390 - precision_8: 0.8942 - recall_8: 0.7161 - auc_8: 0.8687 - specificity_at_sensitivity_5: 0.9949 - val_loss: 0.3644 - val_accuracy: 0.8546 - val_precision_8: 0.9060 - val_recall_8: 0.7428 - val_auc_8: 0.8824 - val_specificity_at_sensitivity_5: 0.9971\n",
      "Epoch 20/50\n",
      "612/612 [==============================] - 29s 48ms/step - loss: 0.3975 - accuracy: 0.8398 - precision_8: 0.8967 - recall_8: 0.7156 - auc_8: 0.8667 - specificity_at_sensitivity_5: 0.9950 - val_loss: 0.3589 - val_accuracy: 0.8609 - val_precision_8: 0.9289 - val_recall_8: 0.7367 - val_auc_8: 0.8793 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 21/50\n",
      "612/612 [==============================] - 27s 45ms/step - loss: 0.3980 - accuracy: 0.8384 - precision_8: 0.8915 - recall_8: 0.7175 - auc_8: 0.8681 - specificity_at_sensitivity_5: 0.9946 - val_loss: 0.3591 - val_accuracy: 0.8595 - val_precision_8: 0.9494 - val_recall_8: 0.7151 - val_auc_8: 0.8831 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 22/50\n",
      "612/612 [==============================] - 27s 45ms/step - loss: 0.3925 - accuracy: 0.8422 - precision_8: 0.8969 - recall_8: 0.7218 - auc_8: 0.8721 - specificity_at_sensitivity_5: 0.9948 - val_loss: 0.3637 - val_accuracy: 0.8580 - val_precision_8: 0.9037 - val_recall_8: 0.7541 - val_auc_8: 0.8789 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 23/50\n",
      "612/612 [==============================] - 29s 47ms/step - loss: 0.3994 - accuracy: 0.8383 - precision_8: 0.8864 - recall_8: 0.7225 - auc_8: 0.8689 - specificity_at_sensitivity_5: 0.9942 - val_loss: 0.3688 - val_accuracy: 0.8574 - val_precision_8: 0.9323 - val_recall_8: 0.7250 - val_auc_8: 0.8791 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 28s 45ms/step - loss: 0.3947 - accuracy: 0.8411 - precision_8: 0.8920 - recall_8: 0.7240 - auc_8: 0.8720 - specificity_at_sensitivity_5: 0.9941 - val_loss: 0.3629 - val_accuracy: 0.8540 - val_precision_8: 0.9063 - val_recall_8: 0.7409 - val_auc_8: 0.8805 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 25/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3953 - accuracy: 0.8405 - precision_8: 0.8951 - recall_8: 0.7191 - auc_8: 0.8702 - specificity_at_sensitivity_5: 0.9944 - val_loss: 0.3685 - val_accuracy: 0.8546 - val_precision_8: 0.8991 - val_recall_8: 0.7499 - val_auc_8: 0.8800 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 26/50\n",
      "612/612 [==============================] - 28s 45ms/step - loss: 0.3962 - accuracy: 0.8389 - precision_8: 0.8922 - recall_8: 0.7179 - auc_8: 0.8695 - specificity_at_sensitivity_5: 0.9961 - val_loss: 0.3639 - val_accuracy: 0.8548 - val_precision_8: 0.9136 - val_recall_8: 0.7358 - val_auc_8: 0.8780 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 27/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3885 - accuracy: 0.8440 - precision_8: 0.9001 - recall_8: 0.7230 - auc_8: 0.8733 - specificity_at_sensitivity_5: 0.9962 - val_loss: 0.3621 - val_accuracy: 0.8613 - val_precision_8: 0.9346 - val_recall_8: 0.7325 - val_auc_8: 0.8788 - val_specificity_at_sensitivity_5: 0.9975\n",
      "Epoch 28/50\n",
      "612/612 [==============================] - 26s 43ms/step - loss: 0.3906 - accuracy: 0.8436 - precision_8: 0.9026 - recall_8: 0.7196 - auc_8: 0.8705 - specificity_at_sensitivity_5: 0.9957 - val_loss: 0.3626 - val_accuracy: 0.8613 - val_precision_8: 0.9571 - val_recall_8: 0.7132 - val_auc_8: 0.8790 - val_specificity_at_sensitivity_5: 0.9989\n",
      "Epoch 29/50\n",
      "612/612 [==============================] - 26s 43ms/step - loss: 0.3917 - accuracy: 0.8430 - precision_8: 0.8965 - recall_8: 0.7243 - auc_8: 0.8726 - specificity_at_sensitivity_5: 0.9937 - val_loss: 0.3624 - val_accuracy: 0.8583 - val_precision_8: 0.9437 - val_recall_8: 0.7170 - val_auc_8: 0.8778 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 30/50\n",
      "612/612 [==============================] - 30s 49ms/step - loss: 0.3897 - accuracy: 0.8464 - precision_8: 0.9068 - recall_8: 0.7225 - auc_8: 0.8709 - specificity_at_sensitivity_5: 0.9949 - val_loss: 0.3591 - val_accuracy: 0.8619 - val_precision_8: 0.9291 - val_recall_8: 0.7391 - val_auc_8: 0.8808 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 31/50\n",
      "612/612 [==============================] - 30s 49ms/step - loss: 0.3907 - accuracy: 0.8430 - precision_8: 0.8972 - recall_8: 0.7236 - auc_8: 0.8722 - specificity_at_sensitivity_5: 0.9942 - val_loss: 0.3599 - val_accuracy: 0.8593 - val_precision_8: 0.9472 - val_recall_8: 0.7165 - val_auc_8: 0.8804 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 32/50\n",
      "612/612 [==============================] - 28s 45ms/step - loss: 0.3865 - accuracy: 0.8441 - precision_8: 0.9018 - recall_8: 0.7217 - auc_8: 0.8734 - specificity_at_sensitivity_5: 0.9962 - val_loss: 0.3702 - val_accuracy: 0.8591 - val_precision_8: 0.9477 - val_recall_8: 0.7156 - val_auc_8: 0.8758 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 33/50\n",
      "612/612 [==============================] - 28s 46ms/step - loss: 0.3982 - accuracy: 0.8408 - precision_8: 0.8990 - recall_8: 0.7161 - auc_8: 0.8689 - specificity_at_sensitivity_5: 0.9945 - val_loss: 0.3568 - val_accuracy: 0.8605 - val_precision_8: 0.9446 - val_recall_8: 0.7217 - val_auc_8: 0.8788 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 34/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3922 - accuracy: 0.8433 - precision_8: 0.9014 - recall_8: 0.7202 - auc_8: 0.8714 - specificity_at_sensitivity_5: 0.9950 - val_loss: 0.3636 - val_accuracy: 0.8570 - val_precision_8: 0.9113 - val_recall_8: 0.7438 - val_auc_8: 0.8813 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 35/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3954 - accuracy: 0.8411 - precision_8: 0.8990 - recall_8: 0.7168 - auc_8: 0.8679 - specificity_at_sensitivity_5: 0.9954 - val_loss: 0.3547 - val_accuracy: 0.8615 - val_precision_8: 0.9336 - val_recall_8: 0.7339 - val_auc_8: 0.8822 - val_specificity_at_sensitivity_5: 0.9982\n",
      "Epoch 36/50\n",
      "612/612 [==============================] - 27s 45ms/step - loss: 0.3938 - accuracy: 0.8417 - precision_8: 0.8968 - recall_8: 0.7205 - auc_8: 0.8713 - specificity_at_sensitivity_5: 0.9946 - val_loss: 0.3640 - val_accuracy: 0.8570 - val_precision_8: 0.9435 - val_recall_8: 0.7142 - val_auc_8: 0.8812 - val_specificity_at_sensitivity_5: 0.9989\n",
      "Epoch 37/50\n",
      "612/612 [==============================] - 29s 47ms/step - loss: 0.3918 - accuracy: 0.8410 - precision_8: 0.8993 - recall_8: 0.7162 - auc_8: 0.8701 - specificity_at_sensitivity_5: 0.9964 - val_loss: 0.3814 - val_accuracy: 0.8427 - val_precision_8: 0.8600 - val_recall_8: 0.7626 - val_auc_8: 0.8789 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 38/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3906 - accuracy: 0.8438 - precision_8: 0.8974 - recall_8: 0.7253 - auc_8: 0.8722 - specificity_at_sensitivity_5: 0.9947 - val_loss: 0.3581 - val_accuracy: 0.8605 - val_precision_8: 0.9329 - val_recall_8: 0.7320 - val_auc_8: 0.8789 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 39/50\n",
      "612/612 [==============================] - 28s 46ms/step - loss: 0.3909 - accuracy: 0.8408 - precision_8: 0.8922 - recall_8: 0.7229 - auc_8: 0.8731 - specificity_at_sensitivity_5: 0.9956 - val_loss: 0.3611 - val_accuracy: 0.8615 - val_precision_8: 0.9492 - val_recall_8: 0.7203 - val_auc_8: 0.8817 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 40/50\n",
      "612/612 [==============================] - 26s 43ms/step - loss: 0.3891 - accuracy: 0.8446 - precision_8: 0.8999 - recall_8: 0.7250 - auc_8: 0.8736 - specificity_at_sensitivity_5: 0.9955 - val_loss: 0.3592 - val_accuracy: 0.8587 - val_precision_8: 0.9165 - val_recall_8: 0.7428 - val_auc_8: 0.8814 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 41/50\n",
      "612/612 [==============================] - 29s 48ms/step - loss: 0.3953 - accuracy: 0.8376 - precision_8: 0.8910 - recall_8: 0.7158 - auc_8: 0.8710 - specificity_at_sensitivity_5: 0.9956 - val_loss: 0.3622 - val_accuracy: 0.8611 - val_precision_8: 0.9294 - val_recall_8: 0.7367 - val_auc_8: 0.8801 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 42/50\n",
      "612/612 [==============================] - 27s 44ms/step - loss: 0.3931 - accuracy: 0.8397 - precision_8: 0.8951 - recall_8: 0.7170 - auc_8: 0.8708 - specificity_at_sensitivity_5: 0.9953 - val_loss: 0.3545 - val_accuracy: 0.8648 - val_precision_8: 0.9475 - val_recall_8: 0.7297 - val_auc_8: 0.8797 - val_specificity_at_sensitivity_5: 0.9978\n",
      "Epoch 43/50\n",
      "612/612 [==============================] - 30s 49ms/step - loss: 0.3892 - accuracy: 0.8437 - precision_8: 0.9008 - recall_8: 0.7216 - auc_8: 0.8722 - specificity_at_sensitivity_5: 0.9956 - val_loss: 0.3760 - val_accuracy: 0.8607 - val_precision_8: 0.9293 - val_recall_8: 0.7358 - val_auc_8: 0.8740 - val_specificity_at_sensitivity_5: 0.9989\n",
      "Epoch 44/50\n",
      "612/612 [==============================] - 28s 45ms/step - loss: 0.3909 - accuracy: 0.8424 - precision_8: 0.8983 - recall_8: 0.7208 - auc_8: 0.8720 - specificity_at_sensitivity_5: 0.9953 - val_loss: 0.3575 - val_accuracy: 0.8623 - val_precision_8: 0.9380 - val_recall_8: 0.7320 - val_auc_8: 0.8769 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 45/50\n",
      "612/612 [==============================] - 28s 46ms/step - loss: 0.3899 - accuracy: 0.8429 - precision_8: 0.9010 - recall_8: 0.7194 - auc_8: 0.8717 - specificity_at_sensitivity_5: 0.9966 - val_loss: 0.3542 - val_accuracy: 0.8603 - val_precision_8: 0.9402 - val_recall_8: 0.7250 - val_auc_8: 0.8803 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 46/50\n",
      "612/612 [==============================] - 31s 50ms/step - loss: 0.3851 - accuracy: 0.8467 - precision_8: 0.9035 - recall_8: 0.7267 - auc_8: 0.8744 - specificity_at_sensitivity_5: 0.9965 - val_loss: 0.3615 - val_accuracy: 0.8593 - val_precision_8: 0.9385 - val_recall_8: 0.7240 - val_auc_8: 0.8812 - val_specificity_at_sensitivity_5: 0.9989\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 28s 46ms/step - loss: 0.3856 - accuracy: 0.8462 - precision_8: 0.9037 - recall_8: 0.7252 - auc_8: 0.8741 - specificity_at_sensitivity_5: 0.9957 - val_loss: 0.3599 - val_accuracy: 0.8601 - val_precision_8: 0.9125 - val_recall_8: 0.7504 - val_auc_8: 0.8804 - val_specificity_at_sensitivity_5: 0.9986\n",
      "Epoch 48/50\n",
      "612/612 [==============================] - 30s 49ms/step - loss: 0.3937 - accuracy: 0.8409 - precision_8: 0.8959 - recall_8: 0.7195 - auc_8: 0.8702 - specificity_at_sensitivity_5: 0.9949 - val_loss: 0.3746 - val_accuracy: 0.8587 - val_precision_8: 0.9674 - val_recall_8: 0.6986 - val_auc_8: 0.8773 - val_specificity_at_sensitivity_5: 0.9996\n",
      "Epoch 49/50\n",
      "612/612 [==============================] - 35s 58ms/step - loss: 0.3888 - accuracy: 0.8449 - precision_8: 0.9029 - recall_8: 0.7226 - auc_8: 0.8723 - specificity_at_sensitivity_5: 0.9947 - val_loss: 0.3547 - val_accuracy: 0.8619 - val_precision_8: 0.9211 - val_recall_8: 0.7466 - val_auc_8: 0.8850 - val_specificity_at_sensitivity_5: 0.9993\n",
      "Epoch 50/50\n",
      "612/612 [==============================] - 37s 60ms/step - loss: 0.3898 - accuracy: 0.8438 - precision_8: 0.8975 - recall_8: 0.7251 - auc_8: 0.8744 - specificity_at_sensitivity_5: 0.9946 - val_loss: 0.3626 - val_accuracy: 0.8613 - val_precision_8: 0.9404 - val_recall_8: 0.7273 - val_auc_8: 0.8795 - val_specificity_at_sensitivity_5: 0.9982\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for Conv1D input\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=3, activation='tanh', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, activation='tanh'))\n",
    "model.add(Conv1D(128, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, activation='tanh'))\n",
    "model.add(Conv1D(256, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC(), keras.metrics.SpecificityAtSensitivity(0.5)])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd6f3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3626 - accuracy: 0.8613 - precision_8: 0.9404 - recall_8: 0.7273 - auc_8: 0.8795 - specificity_at_sensitivity_5: 0.9982\n",
      "Test loss: 0.3625801205635071\n",
      "Test accuracy: 0.8613213300704956\n",
      "Test precision: 0.9404255151748657\n",
      "Test recall: 0.7273154854774475\n",
      "Test F1 score: 0.5127829425401781\n",
      "Test ROC AUC: 0.8794643878936768\n",
      "Test specificity: 0.9996160805991059\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall, auc, fp = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Test precision: {precision}\")\n",
    "print(f\"Test recall: {recall}\")\n",
    "print(f\"Test F1 score: {2*((precision*recall)/(precision+recall+1))}\")\n",
    "print(f\"Test ROC AUC: {auc}\")\n",
    "print(f\"Test specificity: {1-fp/(fp+tn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5575f98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "612/612 [==============================] - 207s 328ms/step - loss: 0.6153 - accuracy: 0.6872 - precision_9: 0.6524 - recall_9: 0.6074 - auc_9: 0.7314 - specificity_at_sensitivity_6: 0.8347 - val_loss: 0.5282 - val_accuracy: 0.7766 - val_precision_9: 0.7295 - val_recall_9: 0.7734 - val_auc_9: 0.8436 - val_specificity_at_sensitivity_6: 0.9638\n",
      "Epoch 2/50\n",
      "612/612 [==============================] - 195s 319ms/step - loss: 0.4859 - accuracy: 0.7885 - precision_9: 0.8153 - recall_9: 0.6669 - auc_9: 0.8231 - specificity_at_sensitivity_6: 0.9642 - val_loss: 0.4850 - val_accuracy: 0.7852 - val_precision_9: 0.7371 - val_recall_9: 0.7870 - val_auc_9: 0.8625 - val_specificity_at_sensitivity_6: 0.9797\n",
      "Epoch 3/50\n",
      "612/612 [==============================] - 1093s 2s/step - loss: 0.4537 - accuracy: 0.8110 - precision_9: 0.8500 - recall_9: 0.6889 - auc_9: 0.8402 - specificity_at_sensitivity_6: 0.9776 - val_loss: 0.4300 - val_accuracy: 0.8251 - val_precision_9: 0.9768 - val_recall_9: 0.6126 - val_auc_9: 0.8702 - val_specificity_at_sensitivity_6: 0.9953\n",
      "Epoch 4/50\n",
      "612/612 [==============================] - 189s 309ms/step - loss: 0.4439 - accuracy: 0.8164 - precision_9: 0.8617 - recall_9: 0.6907 - auc_9: 0.8441 - specificity_at_sensitivity_6: 0.9812 - val_loss: 0.4023 - val_accuracy: 0.8388 - val_precision_9: 0.9502 - val_recall_9: 0.6643 - val_auc_9: 0.8665 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 5/50\n",
      "612/612 [==============================] - 189s 309ms/step - loss: 0.4325 - accuracy: 0.8239 - precision_9: 0.8746 - recall_9: 0.6966 - auc_9: 0.8483 - specificity_at_sensitivity_6: 0.9857 - val_loss: 0.3892 - val_accuracy: 0.8497 - val_precision_9: 0.9118 - val_recall_9: 0.7245 - val_auc_9: 0.8720 - val_specificity_at_sensitivity_6: 0.9935\n",
      "Epoch 6/50\n",
      "612/612 [==============================] - 141s 230ms/step - loss: 0.4273 - accuracy: 0.8263 - precision_9: 0.8800 - recall_9: 0.6975 - auc_9: 0.8497 - specificity_at_sensitivity_6: 0.9860 - val_loss: 0.3813 - val_accuracy: 0.8495 - val_precision_9: 0.9473 - val_recall_9: 0.6925 - val_auc_9: 0.8701 - val_specificity_at_sensitivity_6: 0.9971\n",
      "Epoch 7/50\n",
      "612/612 [==============================] - 75s 122ms/step - loss: 0.4244 - accuracy: 0.8301 - precision_9: 0.8852 - recall_9: 0.7021 - auc_9: 0.8497 - specificity_at_sensitivity_6: 0.9873 - val_loss: 0.4228 - val_accuracy: 0.8355 - val_precision_9: 0.8570 - val_recall_9: 0.7466 - val_auc_9: 0.8653 - val_specificity_at_sensitivity_6: 0.9837\n",
      "Epoch 8/50\n",
      "612/612 [==============================] - 79s 129ms/step - loss: 0.4212 - accuracy: 0.8334 - precision_9: 0.8889 - recall_9: 0.7069 - auc_9: 0.8517 - specificity_at_sensitivity_6: 0.9858 - val_loss: 0.3868 - val_accuracy: 0.8460 - val_precision_9: 0.9220 - val_recall_9: 0.7057 - val_auc_9: 0.8738 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 9/50\n",
      "612/612 [==============================] - 82s 134ms/step - loss: 0.4182 - accuracy: 0.8338 - precision_9: 0.8967 - recall_9: 0.7002 - auc_9: 0.8540 - specificity_at_sensitivity_6: 0.9877 - val_loss: 0.3776 - val_accuracy: 0.8480 - val_precision_9: 0.9619 - val_recall_9: 0.6775 - val_auc_9: 0.8758 - val_specificity_at_sensitivity_6: 0.9967\n",
      "Epoch 10/50\n",
      "612/612 [==============================] - 82s 134ms/step - loss: 0.4142 - accuracy: 0.8358 - precision_9: 0.9000 - recall_9: 0.7021 - auc_9: 0.8531 - specificity_at_sensitivity_6: 0.9904 - val_loss: 0.3842 - val_accuracy: 0.8495 - val_precision_9: 0.9467 - val_recall_9: 0.6930 - val_auc_9: 0.8637 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 11/50\n",
      "612/612 [==============================] - 81s 133ms/step - loss: 0.4134 - accuracy: 0.8374 - precision_9: 0.9025 - recall_9: 0.7037 - auc_9: 0.8549 - specificity_at_sensitivity_6: 0.9888 - val_loss: 0.3804 - val_accuracy: 0.8497 - val_precision_9: 0.9433 - val_recall_9: 0.6963 - val_auc_9: 0.8624 - val_specificity_at_sensitivity_6: 0.9978\n",
      "Epoch 12/50\n",
      "612/612 [==============================] - 83s 135ms/step - loss: 0.4094 - accuracy: 0.8382 - precision_9: 0.8998 - recall_9: 0.7086 - auc_9: 0.8556 - specificity_at_sensitivity_6: 0.9910 - val_loss: 0.3901 - val_accuracy: 0.8497 - val_precision_9: 0.8982 - val_recall_9: 0.7381 - val_auc_9: 0.8702 - val_specificity_at_sensitivity_6: 0.9899\n",
      "Epoch 13/50\n",
      "612/612 [==============================] - 84s 137ms/step - loss: 0.4116 - accuracy: 0.8388 - precision_9: 0.9010 - recall_9: 0.7088 - auc_9: 0.8556 - specificity_at_sensitivity_6: 0.9892 - val_loss: 0.3859 - val_accuracy: 0.8484 - val_precision_9: 0.9381 - val_recall_9: 0.6977 - val_auc_9: 0.8736 - val_specificity_at_sensitivity_6: 0.9935\n",
      "Epoch 14/50\n",
      "612/612 [==============================] - 147s 241ms/step - loss: 0.4118 - accuracy: 0.8385 - precision_9: 0.9032 - recall_9: 0.7059 - auc_9: 0.8535 - specificity_at_sensitivity_6: 0.9886 - val_loss: 0.3784 - val_accuracy: 0.8544 - val_precision_9: 0.9447 - val_recall_9: 0.7066 - val_auc_9: 0.8703 - val_specificity_at_sensitivity_6: 0.9957\n",
      "Epoch 15/50\n",
      "612/612 [==============================] - 81s 133ms/step - loss: 0.4036 - accuracy: 0.8439 - precision_9: 0.9089 - recall_9: 0.7141 - auc_9: 0.8577 - specificity_at_sensitivity_6: 0.9905 - val_loss: 0.3703 - val_accuracy: 0.8558 - val_precision_9: 0.9506 - val_recall_9: 0.7052 - val_auc_9: 0.8711 - val_specificity_at_sensitivity_6: 0.9982\n",
      "Epoch 16/50\n",
      "612/612 [==============================] - 85s 139ms/step - loss: 0.4087 - accuracy: 0.8382 - precision_9: 0.9010 - recall_9: 0.7073 - auc_9: 0.8560 - specificity_at_sensitivity_6: 0.9904 - val_loss: 0.3741 - val_accuracy: 0.8531 - val_precision_9: 0.9428 - val_recall_9: 0.7052 - val_auc_9: 0.8769 - val_specificity_at_sensitivity_6: 0.9982\n",
      "Epoch 17/50\n",
      "612/612 [==============================] - 86s 141ms/step - loss: 0.4002 - accuracy: 0.8472 - precision_9: 0.9158 - recall_9: 0.7160 - auc_9: 0.8579 - specificity_at_sensitivity_6: 0.9906 - val_loss: 0.3744 - val_accuracy: 0.8517 - val_precision_9: 0.9343 - val_recall_9: 0.7090 - val_auc_9: 0.8715 - val_specificity_at_sensitivity_6: 0.9967\n",
      "Epoch 18/50\n",
      "612/612 [==============================] - 144s 236ms/step - loss: 0.4017 - accuracy: 0.8462 - precision_9: 0.9131 - recall_9: 0.7161 - auc_9: 0.8583 - specificity_at_sensitivity_6: 0.9906 - val_loss: 0.3769 - val_accuracy: 0.8540 - val_precision_9: 0.9418 - val_recall_9: 0.7080 - val_auc_9: 0.8718 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 19/50\n",
      "612/612 [==============================] - 76s 123ms/step - loss: 0.3939 - accuracy: 0.8481 - precision_9: 0.9153 - recall_9: 0.7187 - auc_9: 0.8629 - specificity_at_sensitivity_6: 0.9932 - val_loss: 0.3730 - val_accuracy: 0.8585 - val_precision_9: 0.9248 - val_recall_9: 0.7344 - val_auc_9: 0.8692 - val_specificity_at_sensitivity_6: 0.9938\n",
      "Epoch 20/50\n",
      "612/612 [==============================] - 78s 127ms/step - loss: 0.4033 - accuracy: 0.8447 - precision_9: 0.9077 - recall_9: 0.7175 - auc_9: 0.8598 - specificity_at_sensitivity_6: 0.9906 - val_loss: 0.4032 - val_accuracy: 0.8474 - val_precision_9: 0.8868 - val_recall_9: 0.7442 - val_auc_9: 0.8604 - val_specificity_at_sensitivity_6: 0.9783\n",
      "Epoch 21/50\n",
      "612/612 [==============================] - 76s 125ms/step - loss: 0.3995 - accuracy: 0.8439 - precision_9: 0.9063 - recall_9: 0.7167 - auc_9: 0.8617 - specificity_at_sensitivity_6: 0.9926 - val_loss: 0.3798 - val_accuracy: 0.8546 - val_precision_9: 0.9442 - val_recall_9: 0.7076 - val_auc_9: 0.8695 - val_specificity_at_sensitivity_6: 0.9953\n",
      "Epoch 22/50\n",
      "612/612 [==============================] - 77s 126ms/step - loss: 0.4004 - accuracy: 0.8449 - precision_9: 0.9132 - recall_9: 0.7128 - auc_9: 0.8580 - specificity_at_sensitivity_6: 0.9921 - val_loss: 0.3734 - val_accuracy: 0.8523 - val_precision_9: 0.9495 - val_recall_9: 0.6977 - val_auc_9: 0.8730 - val_specificity_at_sensitivity_6: 0.9996\n",
      "Epoch 23/50\n",
      "612/612 [==============================] - 77s 125ms/step - loss: 0.3995 - accuracy: 0.8455 - precision_9: 0.9095 - recall_9: 0.7178 - auc_9: 0.8596 - specificity_at_sensitivity_6: 0.9914 - val_loss: 0.3683 - val_accuracy: 0.8558 - val_precision_9: 0.9523 - val_recall_9: 0.7038 - val_auc_9: 0.8676 - val_specificity_at_sensitivity_6: 0.9978\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 77s 126ms/step - loss: 0.3957 - accuracy: 0.8496 - precision_9: 0.9203 - recall_9: 0.7178 - auc_9: 0.8618 - specificity_at_sensitivity_6: 0.9913 - val_loss: 0.3732 - val_accuracy: 0.8544 - val_precision_9: 0.9348 - val_recall_9: 0.7151 - val_auc_9: 0.8740 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 25/50\n",
      "612/612 [==============================] - 80s 131ms/step - loss: 0.3949 - accuracy: 0.8480 - precision_9: 0.9188 - recall_9: 0.7153 - auc_9: 0.8599 - specificity_at_sensitivity_6: 0.9933 - val_loss: 0.3827 - val_accuracy: 0.8509 - val_precision_9: 0.9078 - val_recall_9: 0.7315 - val_auc_9: 0.8693 - val_specificity_at_sensitivity_6: 0.9917\n",
      "Epoch 26/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.3972 - accuracy: 0.8456 - precision_9: 0.9103 - recall_9: 0.7172 - auc_9: 0.8615 - specificity_at_sensitivity_6: 0.9921 - val_loss: 0.3664 - val_accuracy: 0.8556 - val_precision_9: 0.9148 - val_recall_9: 0.7367 - val_auc_9: 0.8737 - val_specificity_at_sensitivity_6: 0.9986\n",
      "Epoch 27/50\n",
      "612/612 [==============================] - 80s 131ms/step - loss: 0.4025 - accuracy: 0.8420 - precision_9: 0.9024 - recall_9: 0.7157 - auc_9: 0.8594 - specificity_at_sensitivity_6: 0.9905 - val_loss: 0.3850 - val_accuracy: 0.8511 - val_precision_9: 0.8959 - val_recall_9: 0.7442 - val_auc_9: 0.8755 - val_specificity_at_sensitivity_6: 0.9964\n",
      "Epoch 28/50\n",
      "612/612 [==============================] - 79s 129ms/step - loss: 0.3980 - accuracy: 0.8451 - precision_9: 0.9106 - recall_9: 0.7156 - auc_9: 0.8601 - specificity_at_sensitivity_6: 0.9919 - val_loss: 0.3717 - val_accuracy: 0.8544 - val_precision_9: 0.9430 - val_recall_9: 0.7080 - val_auc_9: 0.8737 - val_specificity_at_sensitivity_6: 0.9957\n",
      "Epoch 29/50\n",
      "612/612 [==============================] - 75s 123ms/step - loss: 0.3967 - accuracy: 0.8467 - precision_9: 0.9145 - recall_9: 0.7160 - auc_9: 0.8626 - specificity_at_sensitivity_6: 0.9925 - val_loss: 0.3643 - val_accuracy: 0.8580 - val_precision_9: 0.9377 - val_recall_9: 0.7217 - val_auc_9: 0.8732 - val_specificity_at_sensitivity_6: 0.9989\n",
      "Epoch 30/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.3986 - accuracy: 0.8462 - precision_9: 0.9143 - recall_9: 0.7148 - auc_9: 0.8598 - specificity_at_sensitivity_6: 0.9925 - val_loss: 0.3773 - val_accuracy: 0.8525 - val_precision_9: 0.9175 - val_recall_9: 0.7264 - val_auc_9: 0.8680 - val_specificity_at_sensitivity_6: 0.9909\n",
      "Epoch 31/50\n",
      "612/612 [==============================] - 78s 127ms/step - loss: 0.3957 - accuracy: 0.8457 - precision_9: 0.9067 - recall_9: 0.7210 - auc_9: 0.8659 - specificity_at_sensitivity_6: 0.9921 - val_loss: 0.3670 - val_accuracy: 0.8546 - val_precision_9: 0.9126 - val_recall_9: 0.7362 - val_auc_9: 0.8746 - val_specificity_at_sensitivity_6: 0.9964\n",
      "Epoch 32/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.4008 - accuracy: 0.8446 - precision_9: 0.9148 - recall_9: 0.7103 - auc_9: 0.8570 - specificity_at_sensitivity_6: 0.9940 - val_loss: 0.3665 - val_accuracy: 0.8560 - val_precision_9: 0.9304 - val_recall_9: 0.7231 - val_auc_9: 0.8765 - val_specificity_at_sensitivity_6: 0.9982\n",
      "Epoch 33/50\n",
      "612/612 [==============================] - 77s 125ms/step - loss: 0.3995 - accuracy: 0.8461 - precision_9: 0.9114 - recall_9: 0.7175 - auc_9: 0.8584 - specificity_at_sensitivity_6: 0.9916 - val_loss: 0.3689 - val_accuracy: 0.8599 - val_precision_9: 0.9418 - val_recall_9: 0.7226 - val_auc_9: 0.8699 - val_specificity_at_sensitivity_6: 0.9942\n",
      "Epoch 34/50\n",
      "612/612 [==============================] - 77s 125ms/step - loss: 0.3992 - accuracy: 0.8480 - precision_9: 0.9155 - recall_9: 0.7182 - auc_9: 0.8585 - specificity_at_sensitivity_6: 0.9904 - val_loss: 0.3709 - val_accuracy: 0.8564 - val_precision_9: 0.9606 - val_recall_9: 0.6986 - val_auc_9: 0.8740 - val_specificity_at_sensitivity_6: 0.9967\n",
      "Epoch 35/50\n",
      "612/612 [==============================] - 76s 125ms/step - loss: 0.3950 - accuracy: 0.8461 - precision_9: 0.9131 - recall_9: 0.7158 - auc_9: 0.8647 - specificity_at_sensitivity_6: 0.9921 - val_loss: 0.3776 - val_accuracy: 0.8507 - val_precision_9: 0.9480 - val_recall_9: 0.6949 - val_auc_9: 0.8667 - val_specificity_at_sensitivity_6: 0.9982\n",
      "Epoch 36/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.3961 - accuracy: 0.8468 - precision_9: 0.9174 - recall_9: 0.7135 - auc_9: 0.8601 - specificity_at_sensitivity_6: 0.9927 - val_loss: 0.3718 - val_accuracy: 0.8568 - val_precision_9: 0.9195 - val_recall_9: 0.7353 - val_auc_9: 0.8686 - val_specificity_at_sensitivity_6: 0.9946\n",
      "Epoch 37/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.3949 - accuracy: 0.8477 - precision_9: 0.9119 - recall_9: 0.7210 - auc_9: 0.8616 - specificity_at_sensitivity_6: 0.9916 - val_loss: 0.3804 - val_accuracy: 0.8517 - val_precision_9: 0.8929 - val_recall_9: 0.7489 - val_auc_9: 0.8735 - val_specificity_at_sensitivity_6: 0.9960\n",
      "Epoch 38/50\n",
      "612/612 [==============================] - 78s 127ms/step - loss: 0.3984 - accuracy: 0.8449 - precision_9: 0.9132 - recall_9: 0.7128 - auc_9: 0.8612 - specificity_at_sensitivity_6: 0.9926 - val_loss: 0.3715 - val_accuracy: 0.8540 - val_precision_9: 0.9645 - val_recall_9: 0.6897 - val_auc_9: 0.8610 - val_specificity_at_sensitivity_6: 0.9986\n",
      "Epoch 39/50\n",
      "612/612 [==============================] - 76s 125ms/step - loss: 0.3992 - accuracy: 0.8434 - precision_9: 0.9062 - recall_9: 0.7156 - auc_9: 0.8602 - specificity_at_sensitivity_6: 0.9926 - val_loss: 0.3750 - val_accuracy: 0.8529 - val_precision_9: 0.9384 - val_recall_9: 0.7085 - val_auc_9: 0.8661 - val_specificity_at_sensitivity_6: 0.9942\n",
      "Epoch 40/50\n",
      "612/612 [==============================] - 78s 128ms/step - loss: 0.3985 - accuracy: 0.8443 - precision_9: 0.9097 - recall_9: 0.7144 - auc_9: 0.8650 - specificity_at_sensitivity_6: 0.9915 - val_loss: 0.3740 - val_accuracy: 0.8486 - val_precision_9: 0.8956 - val_recall_9: 0.7381 - val_auc_9: 0.8747 - val_specificity_at_sensitivity_6: 0.9953\n",
      "Epoch 41/50\n",
      "612/612 [==============================] - 77s 125ms/step - loss: 0.3988 - accuracy: 0.8426 - precision_9: 0.9032 - recall_9: 0.7164 - auc_9: 0.8627 - specificity_at_sensitivity_6: 0.9924 - val_loss: 0.3804 - val_accuracy: 0.8495 - val_precision_9: 0.8967 - val_recall_9: 0.7391 - val_auc_9: 0.8741 - val_specificity_at_sensitivity_6: 0.9942\n",
      "Epoch 42/50\n",
      "612/612 [==============================] - 77s 126ms/step - loss: 0.4007 - accuracy: 0.8435 - precision_9: 0.9047 - recall_9: 0.7171 - auc_9: 0.8619 - specificity_at_sensitivity_6: 0.9920 - val_loss: 0.3674 - val_accuracy: 0.8562 - val_precision_9: 0.9478 - val_recall_9: 0.7085 - val_auc_9: 0.8683 - val_specificity_at_sensitivity_6: 0.9953\n",
      "Epoch 43/50\n",
      "612/612 [==============================] - 80s 130ms/step - loss: 0.3987 - accuracy: 0.8467 - precision_9: 0.9177 - recall_9: 0.7130 - auc_9: 0.8593 - specificity_at_sensitivity_6: 0.9926 - val_loss: 0.3835 - val_accuracy: 0.8505 - val_precision_9: 0.9053 - val_recall_9: 0.7330 - val_auc_9: 0.8658 - val_specificity_at_sensitivity_6: 0.9884\n",
      "Epoch 44/50\n",
      "612/612 [==============================] - 76s 125ms/step - loss: 0.4033 - accuracy: 0.8417 - precision_9: 0.9035 - recall_9: 0.7137 - auc_9: 0.8600 - specificity_at_sensitivity_6: 0.9922 - val_loss: 0.3680 - val_accuracy: 0.8552 - val_precision_9: 0.9272 - val_recall_9: 0.7240 - val_auc_9: 0.8735 - val_specificity_at_sensitivity_6: 0.9964\n",
      "Epoch 45/50\n",
      "612/612 [==============================] - 78s 127ms/step - loss: 0.3998 - accuracy: 0.8440 - precision_9: 0.9108 - recall_9: 0.7126 - auc_9: 0.8601 - specificity_at_sensitivity_6: 0.9927 - val_loss: 0.3801 - val_accuracy: 0.8513 - val_precision_9: 0.9353 - val_recall_9: 0.7071 - val_auc_9: 0.8680 - val_specificity_at_sensitivity_6: 0.9971\n",
      "Epoch 46/50\n",
      "612/612 [==============================] - 77s 126ms/step - loss: 0.4047 - accuracy: 0.8422 - precision_9: 0.9021 - recall_9: 0.7164 - auc_9: 0.8597 - specificity_at_sensitivity_6: 0.9896 - val_loss: 0.4054 - val_accuracy: 0.8339 - val_precision_9: 0.9740 - val_recall_9: 0.6352 - val_auc_9: 0.8624 - val_specificity_at_sensitivity_6: 0.9989\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 78s 127ms/step - loss: 0.4020 - accuracy: 0.8425 - precision_9: 0.9049 - recall_9: 0.7144 - auc_9: 0.8592 - specificity_at_sensitivity_6: 0.9917 - val_loss: 0.3756 - val_accuracy: 0.8519 - val_precision_9: 0.9612 - val_recall_9: 0.6874 - val_auc_9: 0.8680 - val_specificity_at_sensitivity_6: 0.9964\n",
      "Epoch 48/50\n",
      "612/612 [==============================] - 76s 124ms/step - loss: 0.4026 - accuracy: 0.8411 - precision_9: 0.9118 - recall_9: 0.7045 - auc_9: 0.8567 - specificity_at_sensitivity_6: 0.9932 - val_loss: 0.3725 - val_accuracy: 0.8566 - val_precision_9: 0.9571 - val_recall_9: 0.7019 - val_auc_9: 0.8730 - val_specificity_at_sensitivity_6: 0.9986\n",
      "Epoch 49/50\n",
      "612/612 [==============================] - 76s 125ms/step - loss: 0.3987 - accuracy: 0.8437 - precision_9: 0.9100 - recall_9: 0.7127 - auc_9: 0.8591 - specificity_at_sensitivity_6: 0.9926 - val_loss: 0.3718 - val_accuracy: 0.8529 - val_precision_9: 0.9700 - val_recall_9: 0.6831 - val_auc_9: 0.8640 - val_specificity_at_sensitivity_6: 0.9975\n",
      "Epoch 50/50\n",
      "612/612 [==============================] - 80s 130ms/step - loss: 0.3981 - accuracy: 0.8468 - precision_9: 0.9124 - recall_9: 0.7183 - auc_9: 0.8606 - specificity_at_sensitivity_6: 0.9921 - val_loss: 0.3734 - val_accuracy: 0.8531 - val_precision_9: 0.9314 - val_recall_9: 0.7151 - val_auc_9: 0.8717 - val_specificity_at_sensitivity_6: 0.9971\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data for Conv1D input\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout,BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=3, activation='tanh', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, activation='tanh'))\n",
    "model.add(Conv1D(128, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, activation='tanh'))\n",
    "model.add(Conv1D(256, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(512, kernel_size=3, activation='tanh'))\n",
    "model.add(Conv1D(512, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.AUC(), keras.metrics.SpecificityAtSensitivity(0.5)])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e7c2406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 3s 21ms/step - loss: 0.3734 - accuracy: 0.8531 - precision_9: 0.9314 - recall_9: 0.7151 - auc_9: 0.8717 - specificity_at_sensitivity_6: 0.9971\n",
      "Test loss: 0.37337014079093933\n",
      "Test accuracy: 0.8531396985054016\n",
      "Test precision: 0.9314146041870117\n",
      "Test recall: 0.7150917053222656\n",
      "Test F1 score: 0.5033404645792464\n",
      "Test ROC AUC: 0.8716849088668823\n",
      "Test specificity: 0.9996164981989704\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy, precision, recall, auc, fp = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "print(f\"Test precision: {precision}\")\n",
    "print(f\"Test recall: {recall}\")\n",
    "print(f\"Test F1 score: {2*((precision*recall)/(precision+recall+1))}\")\n",
    "print(f\"Test ROC AUC: {auc}\")\n",
    "print(f\"Test specificity: {1-fp/(fp+tn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99432c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Epoch 1/15\n",
      "510/510 [==============================] - 14s 21ms/step - loss: 5.2223e-08 - accuracy: 0.5109\n",
      "Epoch 2/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5111\n",
      "Epoch 3/15\n",
      "510/510 [==============================] - 10s 21ms/step - loss: 5.2223e-08 - accuracy: 0.5052\n",
      "Epoch 4/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5099\n",
      "Epoch 5/15\n",
      "510/510 [==============================] - 11s 21ms/step - loss: 5.2223e-08 - accuracy: 0.5103\n",
      "Epoch 6/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5085\n",
      "Epoch 7/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5123\n",
      "Epoch 8/15\n",
      "510/510 [==============================] - 10s 21ms/step - loss: 5.2223e-08 - accuracy: 0.5119\n",
      "Epoch 9/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5104\n",
      "Epoch 10/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5102\n",
      "Epoch 11/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5105\n",
      "Epoch 12/15\n",
      "510/510 [==============================] - 10s 21ms/step - loss: 5.2223e-08 - accuracy: 0.5071\n",
      "Epoch 13/15\n",
      "510/510 [==============================] - 10s 19ms/step - loss: 5.2223e-08 - accuracy: 0.5158\n",
      "Epoch 14/15\n",
      "510/510 [==============================] - 8s 16ms/step - loss: 5.2223e-08 - accuracy: 0.5181\n",
      "Epoch 15/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.2223e-08 - accuracy: 0.5134\n",
      "255/255 [==============================] - 2s 6ms/step - loss: 5.1646e-08 - accuracy: 0.4752\n",
      "Accuracy: 0.4752086400985718\n",
      "Fold: 2\n",
      "Epoch 1/15\n",
      "510/510 [==============================] - 15s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5373\n",
      "Epoch 2/15\n",
      "510/510 [==============================] - 11s 21ms/step - loss: 5.1839e-08 - accuracy: 0.5375\n",
      "Epoch 3/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5445\n",
      "Epoch 4/15\n",
      "510/510 [==============================] - 12s 24ms/step - loss: 5.1839e-08 - accuracy: 0.5354\n",
      "Epoch 5/15\n",
      "510/510 [==============================] - 399s 784ms/step - loss: 5.1839e-08 - accuracy: 0.5367\n",
      "Epoch 6/15\n",
      "510/510 [==============================] - 10s 20ms/step - loss: 5.1839e-08 - accuracy: 0.5381\n",
      "Epoch 7/15\n",
      "510/510 [==============================] - 12s 23ms/step - loss: 5.1839e-08 - accuracy: 0.5384\n",
      "Epoch 8/15\n",
      "510/510 [==============================] - 12s 23ms/step - loss: 5.1839e-08 - accuracy: 0.5351\n",
      "Epoch 9/15\n",
      "510/510 [==============================] - 12s 23ms/step - loss: 5.1839e-08 - accuracy: 0.5359\n",
      "Epoch 10/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5343\n",
      "Epoch 11/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5363\n",
      "Epoch 12/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5407\n",
      "Epoch 13/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5369\n",
      "Epoch 14/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5381\n",
      "Epoch 15/15\n",
      "510/510 [==============================] - 11s 22ms/step - loss: 5.1839e-08 - accuracy: 0.5399\n",
      "255/255 [==============================] - 2s 6ms/step - loss: 5.2413e-08 - accuracy: 0.5595\n",
      "Accuracy: 0.5594697594642639\n",
      "Fold: 3\n",
      "Epoch 1/15\n",
      "510/510 [==============================] - 19s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5461\n",
      "Epoch 2/15\n",
      "510/510 [==============================] - 14s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5492\n",
      "Epoch 3/15\n",
      "510/510 [==============================] - 14s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5446\n",
      "Epoch 4/15\n",
      "510/510 [==============================] - 13s 26ms/step - loss: 5.2029e-08 - accuracy: 0.5442\n",
      "Epoch 5/15\n",
      "510/510 [==============================] - 13s 26ms/step - loss: 5.2029e-08 - accuracy: 0.5433\n",
      "Epoch 6/15\n",
      "510/510 [==============================] - 13s 25ms/step - loss: 5.2029e-08 - accuracy: 0.5424\n",
      "Epoch 7/15\n",
      "510/510 [==============================] - 13s 25ms/step - loss: 5.2029e-08 - accuracy: 0.5448\n",
      "Epoch 8/15\n",
      "510/510 [==============================] - 14s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5442\n",
      "Epoch 9/15\n",
      "510/510 [==============================] - 12s 24ms/step - loss: 5.2029e-08 - accuracy: 0.5462\n",
      "Epoch 10/15\n",
      "510/510 [==============================] - 14s 28ms/step - loss: 5.2029e-08 - accuracy: 0.5377\n",
      "Epoch 11/15\n",
      "510/510 [==============================] - 14s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5430\n",
      "Epoch 12/15\n",
      "510/510 [==============================] - 14s 28ms/step - loss: 5.2029e-08 - accuracy: 0.5410\n",
      "Epoch 13/15\n",
      "510/510 [==============================] - 14s 28ms/step - loss: 5.2029e-08 - accuracy: 0.5418\n",
      "Epoch 14/15\n",
      "510/510 [==============================] - 14s 27ms/step - loss: 5.2029e-08 - accuracy: 0.5436\n",
      "Epoch 15/15\n",
      "510/510 [==============================] - 17s 33ms/step - loss: 5.2029e-08 - accuracy: 0.5391\n",
      "255/255 [==============================] - 3s 8ms/step - loss: 5.2032e-08 - accuracy: 0.5606\n",
      "Accuracy: 0.560574471950531\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense,BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters=32, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(filters=8, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model .add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 3\n",
    "\n",
    "# Define the cross-validation splits\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# Iterate through the folds\n",
    "fold = 0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    fold += 1\n",
    "    print('Fold:', fold)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Reshape the data for the CNN\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=32)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c534d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4403a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
