{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1c15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('updated_coughvid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2650c66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spec_cent</th>\n",
       "      <th>spec_bw</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zcr</th>\n",
       "      <th>mfcc{1}</th>\n",
       "      <th>mfcc{2}</th>\n",
       "      <th>mfcc{3}</th>\n",
       "      <th>mfcc{4}</th>\n",
       "      <th>...</th>\n",
       "      <th>rapJitter</th>\n",
       "      <th>ppq5Jitter</th>\n",
       "      <th>ddpJitter</th>\n",
       "      <th>localShimmer</th>\n",
       "      <th>localdbShimmer</th>\n",
       "      <th>apq3Shimmer</th>\n",
       "      <th>aqpq5Shimmer</th>\n",
       "      <th>apq11Shimmer</th>\n",
       "      <th>ddaShimmer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.254391</td>\n",
       "      <td>1474.950688</td>\n",
       "      <td>1124.906328</td>\n",
       "      <td>2747.482910</td>\n",
       "      <td>0.090097</td>\n",
       "      <td>-587.59827</td>\n",
       "      <td>33.702328</td>\n",
       "      <td>-20.001488</td>\n",
       "      <td>11.846138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.200052</td>\n",
       "      <td>1.789535</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.120025</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.249111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019885</td>\n",
       "      <td>0.471959</td>\n",
       "      <td>3033.833649</td>\n",
       "      <td>1942.259396</td>\n",
       "      <td>5049.260066</td>\n",
       "      <td>0.274662</td>\n",
       "      <td>-498.65125</td>\n",
       "      <td>33.589527</td>\n",
       "      <td>-9.541874</td>\n",
       "      <td>5.552917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>0.078159</td>\n",
       "      <td>0.156720</td>\n",
       "      <td>1.463282</td>\n",
       "      <td>0.064457</td>\n",
       "      <td>0.098804</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.193371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.490168</td>\n",
       "      <td>2382.528337</td>\n",
       "      <td>1989.209603</td>\n",
       "      <td>4572.138209</td>\n",
       "      <td>0.152117</td>\n",
       "      <td>-448.61032</td>\n",
       "      <td>50.123460</td>\n",
       "      <td>-2.242359</td>\n",
       "      <td>14.070694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031386</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.094157</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>1.122052</td>\n",
       "      <td>0.055099</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.157936</td>\n",
       "      <td>0.165297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.402272</td>\n",
       "      <td>3059.483505</td>\n",
       "      <td>2755.704595</td>\n",
       "      <td>6342.833363</td>\n",
       "      <td>0.353009</td>\n",
       "      <td>-551.23260</td>\n",
       "      <td>7.781494</td>\n",
       "      <td>-1.353154</td>\n",
       "      <td>-2.897661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028828</td>\n",
       "      <td>0.044257</td>\n",
       "      <td>0.086483</td>\n",
       "      <td>0.205156</td>\n",
       "      <td>1.808642</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.071324</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.200389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.337257</td>\n",
       "      <td>2907.384300</td>\n",
       "      <td>2203.496570</td>\n",
       "      <td>5332.134031</td>\n",
       "      <td>0.235049</td>\n",
       "      <td>-561.97394</td>\n",
       "      <td>30.249930</td>\n",
       "      <td>-12.876205</td>\n",
       "      <td>1.117003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.041934</td>\n",
       "      <td>0.182836</td>\n",
       "      <td>1.433502</td>\n",
       "      <td>0.073766</td>\n",
       "      <td>0.090565</td>\n",
       "      <td>0.121695</td>\n",
       "      <td>0.221298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.365302</td>\n",
       "      <td>1888.916273</td>\n",
       "      <td>1317.861369</td>\n",
       "      <td>3336.830060</td>\n",
       "      <td>0.144843</td>\n",
       "      <td>-495.00058</td>\n",
       "      <td>42.286800</td>\n",
       "      <td>-23.322453</td>\n",
       "      <td>13.126045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011581</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.184247</td>\n",
       "      <td>1.617661</td>\n",
       "      <td>0.080715</td>\n",
       "      <td>0.078639</td>\n",
       "      <td>0.043619</td>\n",
       "      <td>0.242144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24438</th>\n",
       "      <td>0.023443</td>\n",
       "      <td>0.329975</td>\n",
       "      <td>2155.073625</td>\n",
       "      <td>2015.874664</td>\n",
       "      <td>4467.530218</td>\n",
       "      <td>0.091078</td>\n",
       "      <td>-452.56842</td>\n",
       "      <td>26.401793</td>\n",
       "      <td>-9.079344</td>\n",
       "      <td>18.930265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026902</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.080707</td>\n",
       "      <td>0.202993</td>\n",
       "      <td>1.732378</td>\n",
       "      <td>0.113560</td>\n",
       "      <td>0.156229</td>\n",
       "      <td>0.078076</td>\n",
       "      <td>0.340681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24439</th>\n",
       "      <td>0.035895</td>\n",
       "      <td>0.341938</td>\n",
       "      <td>3758.382614</td>\n",
       "      <td>2346.317397</td>\n",
       "      <td>6451.898506</td>\n",
       "      <td>0.292356</td>\n",
       "      <td>-421.37695</td>\n",
       "      <td>-0.529201</td>\n",
       "      <td>-23.392963</td>\n",
       "      <td>2.227374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.026407</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>0.201879</td>\n",
       "      <td>1.769145</td>\n",
       "      <td>0.104641</td>\n",
       "      <td>0.108829</td>\n",
       "      <td>0.214208</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24440</th>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.164139</td>\n",
       "      <td>818.213855</td>\n",
       "      <td>698.924333</td>\n",
       "      <td>1537.092928</td>\n",
       "      <td>0.040371</td>\n",
       "      <td>-570.10645</td>\n",
       "      <td>22.468716</td>\n",
       "      <td>-5.282608</td>\n",
       "      <td>5.789618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.029620</td>\n",
       "      <td>0.076486</td>\n",
       "      <td>0.185339</td>\n",
       "      <td>1.623609</td>\n",
       "      <td>0.086173</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.258518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24441</th>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.572020</td>\n",
       "      <td>2949.114122</td>\n",
       "      <td>2290.612721</td>\n",
       "      <td>5584.804380</td>\n",
       "      <td>0.233379</td>\n",
       "      <td>-500.92868</td>\n",
       "      <td>22.766354</td>\n",
       "      <td>-6.330773</td>\n",
       "      <td>9.648826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016576</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.049727</td>\n",
       "      <td>0.183851</td>\n",
       "      <td>1.332506</td>\n",
       "      <td>0.084714</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.254141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24442 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rmse  chroma_stft    spec_cent      spec_bw      rolloff       zcr  \\\n",
       "0      0.008606     0.254391  1474.950688  1124.906328  2747.482910  0.090097   \n",
       "1      0.019885     0.471959  3033.833649  1942.259396  5049.260066  0.274662   \n",
       "2      0.015889     0.490168  2382.528337  1989.209603  4572.138209  0.152117   \n",
       "3      0.004452     0.402272  3059.483505  2755.704595  6342.833363  0.353009   \n",
       "4      0.006003     0.337257  2907.384300  2203.496570  5332.134031  0.235049   \n",
       "...         ...          ...          ...          ...          ...       ...   \n",
       "24437  0.010895     0.365302  1888.916273  1317.861369  3336.830060  0.144843   \n",
       "24438  0.023443     0.329975  2155.073625  2015.874664  4467.530218  0.091078   \n",
       "24439  0.035895     0.341938  3758.382614  2346.317397  6451.898506  0.292356   \n",
       "24440  0.010267     0.164139   818.213855   698.924333  1537.092928  0.040371   \n",
       "24441  0.019561     0.572020  2949.114122  2290.612721  5584.804380  0.233379   \n",
       "\n",
       "         mfcc{1}    mfcc{2}    mfcc{3}    mfcc{4}  ...  rapJitter  ppq5Jitter  \\\n",
       "0     -587.59827  33.702328 -20.001488  11.846138  ...   0.018187    0.021293   \n",
       "1     -498.65125  33.589527  -9.541874   5.552917  ...   0.026053    0.032284   \n",
       "2     -448.61032  50.123460  -2.242359  14.070694  ...   0.031386    0.023950   \n",
       "3     -551.23260   7.781494  -1.353154  -2.897661  ...   0.028828    0.044257   \n",
       "4     -561.97394  30.249930 -12.876205   1.117003  ...   0.013978    0.015078   \n",
       "...          ...        ...        ...        ...  ...        ...         ...   \n",
       "24437 -495.00058  42.286800 -23.322453  13.126045  ...   0.011581    0.008284   \n",
       "24438 -452.56842  26.401793  -9.079344  18.930265  ...   0.026902    0.037506   \n",
       "24439 -421.37695  -0.529201 -23.392963   2.227374  ...   0.015663    0.026407   \n",
       "24440 -570.10645  22.468716  -5.282608   5.789618  ...   0.025495    0.029620   \n",
       "24441 -500.92868  22.766354  -6.330773   9.648826  ...   0.016576    0.023900   \n",
       "\n",
       "       ddpJitter  localShimmer  localdbShimmer  apq3Shimmer  aqpq5Shimmer  \\\n",
       "0       0.054561      0.200052        1.789535     0.083037      0.120025   \n",
       "1       0.078159      0.156720        1.463282     0.064457      0.098804   \n",
       "2       0.094157      0.116099        1.122052     0.055099      0.090335   \n",
       "3       0.086483      0.205156        1.808642     0.066796      0.071324   \n",
       "4       0.041934      0.182836        1.433502     0.073766      0.090565   \n",
       "...          ...           ...             ...          ...           ...   \n",
       "24437   0.034743      0.184247        1.617661     0.080715      0.078639   \n",
       "24438   0.080707      0.202993        1.732378     0.113560      0.156229   \n",
       "24439   0.046989      0.201879        1.769145     0.104641      0.108829   \n",
       "24440   0.076486      0.185339        1.623609     0.086173      0.115681   \n",
       "24441   0.049727      0.183851        1.332506     0.084714      0.045647   \n",
       "\n",
       "       apq11Shimmer  ddaShimmer  label  \n",
       "0          0.160610    0.249111      1  \n",
       "1          0.160610    0.193371      0  \n",
       "2          0.157936    0.165297      0  \n",
       "3          0.160610    0.200389      0  \n",
       "4          0.121695    0.221298      0  \n",
       "...             ...         ...    ...  \n",
       "24437      0.043619    0.242144      1  \n",
       "24438      0.078076    0.340681      1  \n",
       "24439      0.214208    0.313924      1  \n",
       "24440      0.160610    0.258518      0  \n",
       "24441      0.160610    0.254141      1  \n",
       "\n",
       "[24442 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7467b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2f993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('label', axis=1), df['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96d7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a50ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa99fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANMUKH\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(50, 50), max_iter=500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the MLP model and set the hyperparameters\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 50), activation='logistic', solver='adam', max_iter=500)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477efbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ea5c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822037365334788\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2115f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.822037365334788\n",
      "Precision: 0.8174789915966386\n",
      "Recall: 0.7614276768941766\n",
      "F1 Score: 0.7884584211379478\n",
      "ROC AUC: 0.8151182839653294\n",
      "Specificity: 0.8688088910364823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model on test set\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "precision = precision_score(y_test, y_pred.round())\n",
    "recall = recall_score(y_test, y_pred.round())\n",
    "f1 = f1_score(y_test, y_pred.round())\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred.round()).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c94b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "535/535 [==============================] - 6s 6ms/step - loss: 0.5236 - accuracy: 0.7583 - val_loss: 0.3985 - val_accuracy: 0.8409\n",
      "Epoch 2/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.4087 - accuracy: 0.8386 - val_loss: 0.3659 - val_accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3692 - accuracy: 0.8567 - val_loss: 0.3506 - val_accuracy: 0.8627\n",
      "Epoch 4/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3504 - accuracy: 0.8667 - val_loss: 0.3397 - val_accuracy: 0.8688\n",
      "Epoch 5/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3436 - accuracy: 0.8689 - val_loss: 0.3371 - val_accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "535/535 [==============================] - 2s 4ms/step - loss: 0.3338 - accuracy: 0.8733 - val_loss: 0.3429 - val_accuracy: 0.8694\n",
      "Epoch 7/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3286 - accuracy: 0.8749 - val_loss: 0.3319 - val_accuracy: 0.8730\n",
      "Epoch 8/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3282 - accuracy: 0.8739 - val_loss: 0.3321 - val_accuracy: 0.8741\n",
      "Epoch 9/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3227 - accuracy: 0.8777 - val_loss: 0.3387 - val_accuracy: 0.8704\n",
      "Epoch 10/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3225 - accuracy: 0.8759 - val_loss: 0.3322 - val_accuracy: 0.8718\n",
      "Epoch 11/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3168 - accuracy: 0.8792 - val_loss: 0.3328 - val_accuracy: 0.8722\n",
      "Epoch 12/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3153 - accuracy: 0.8802 - val_loss: 0.3335 - val_accuracy: 0.8736\n",
      "Epoch 13/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3149 - accuracy: 0.8799 - val_loss: 0.3318 - val_accuracy: 0.8734\n",
      "Epoch 14/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3140 - accuracy: 0.8809 - val_loss: 0.3329 - val_accuracy: 0.8730\n",
      "Epoch 15/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3141 - accuracy: 0.8790 - val_loss: 0.3297 - val_accuracy: 0.8751\n",
      "Epoch 16/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3109 - accuracy: 0.8806 - val_loss: 0.3354 - val_accuracy: 0.8741\n",
      "Epoch 17/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3083 - accuracy: 0.8825 - val_loss: 0.3345 - val_accuracy: 0.8734\n",
      "Epoch 18/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3068 - accuracy: 0.8839 - val_loss: 0.3330 - val_accuracy: 0.8755\n",
      "Epoch 19/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3039 - accuracy: 0.8842 - val_loss: 0.3349 - val_accuracy: 0.8767\n",
      "Epoch 20/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3047 - accuracy: 0.8842 - val_loss: 0.3357 - val_accuracy: 0.8748\n",
      "Epoch 21/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3077 - accuracy: 0.8830 - val_loss: 0.3376 - val_accuracy: 0.8759\n",
      "Epoch 22/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3035 - accuracy: 0.8844 - val_loss: 0.3379 - val_accuracy: 0.8755\n",
      "Epoch 23/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.3048 - accuracy: 0.8842 - val_loss: 0.3372 - val_accuracy: 0.8754\n",
      "Epoch 24/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3034 - accuracy: 0.8843 - val_loss: 0.3416 - val_accuracy: 0.8752\n",
      "Epoch 25/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.3002 - accuracy: 0.8858 - val_loss: 0.3429 - val_accuracy: 0.8751\n",
      "Epoch 26/50\n",
      "535/535 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.8857 - val_loss: 0.3479 - val_accuracy: 0.8740\n",
      "Epoch 27/50\n",
      "535/535 [==============================] - 2s 4ms/step - loss: 0.2995 - accuracy: 0.8860 - val_loss: 0.3373 - val_accuracy: 0.8755\n",
      "Epoch 28/50\n",
      "535/535 [==============================] - 2s 5ms/step - loss: 0.2982 - accuracy: 0.8864 - val_loss: 0.3387 - val_accuracy: 0.8767\n",
      "Epoch 29/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2963 - accuracy: 0.8874 - val_loss: 0.3493 - val_accuracy: 0.8751\n",
      "Epoch 30/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2959 - accuracy: 0.8868 - val_loss: 0.3496 - val_accuracy: 0.8743\n",
      "Epoch 31/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2955 - accuracy: 0.8873 - val_loss: 0.3459 - val_accuracy: 0.8755\n",
      "Epoch 32/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2987 - accuracy: 0.8873 - val_loss: 0.3392 - val_accuracy: 0.8759\n",
      "Epoch 33/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2946 - accuracy: 0.8873 - val_loss: 0.3428 - val_accuracy: 0.8755\n",
      "Epoch 34/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2931 - accuracy: 0.8886 - val_loss: 0.3441 - val_accuracy: 0.8755\n",
      "Epoch 35/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2958 - accuracy: 0.8880 - val_loss: 0.3410 - val_accuracy: 0.8752\n",
      "Epoch 36/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2929 - accuracy: 0.8887 - val_loss: 0.3405 - val_accuracy: 0.8756\n",
      "Epoch 37/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2945 - accuracy: 0.8876 - val_loss: 0.3432 - val_accuracy: 0.8760\n",
      "Epoch 38/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2892 - accuracy: 0.8889 - val_loss: 0.3480 - val_accuracy: 0.8732\n",
      "Epoch 39/50\n",
      "535/535 [==============================] - 3s 6ms/step - loss: 0.2916 - accuracy: 0.8892 - val_loss: 0.3535 - val_accuracy: 0.8700\n",
      "Epoch 40/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2916 - accuracy: 0.8893 - val_loss: 0.3440 - val_accuracy: 0.8749\n",
      "Epoch 41/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2883 - accuracy: 0.8898 - val_loss: 0.3488 - val_accuracy: 0.8739\n",
      "Epoch 42/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2893 - accuracy: 0.8899 - val_loss: 0.3492 - val_accuracy: 0.8745\n",
      "Epoch 43/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2888 - accuracy: 0.8905 - val_loss: 0.3448 - val_accuracy: 0.8748\n",
      "Epoch 44/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2888 - accuracy: 0.8889 - val_loss: 0.3502 - val_accuracy: 0.8751\n",
      "Epoch 45/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2887 - accuracy: 0.8888 - val_loss: 0.3467 - val_accuracy: 0.8760\n",
      "Epoch 46/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2870 - accuracy: 0.8914 - val_loss: 0.3517 - val_accuracy: 0.8743\n",
      "Epoch 47/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2882 - accuracy: 0.8901 - val_loss: 0.3497 - val_accuracy: 0.8747\n",
      "Epoch 48/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2899 - accuracy: 0.8905 - val_loss: 0.3497 - val_accuracy: 0.8740\n",
      "Epoch 49/50\n",
      "535/535 [==============================] - 3s 6ms/step - loss: 0.2850 - accuracy: 0.8908 - val_loss: 0.3437 - val_accuracy: 0.8741\n",
      "Epoch 50/50\n",
      "535/535 [==============================] - 3s 5ms/step - loss: 0.2835 - accuracy: 0.8915 - val_loss: 0.3506 - val_accuracy: 0.8748\n",
      "230/230 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.8748124914768853\n",
      "Precision: 0.9729842061512884\n",
      "Recall: 0.7329367564182843\n",
      "F1-score: 0.8360714285714285\n",
      "ROC AUC: 0.8586162400115099\n",
      "Specificity: 0.9842957236047355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "spec = tn / (tn+fp)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Accuracy:', acc)\n",
    "print('Precision:', prec)\n",
    "print('Recall:', rec)\n",
    "print('F1-score:', f1)\n",
    "print('ROC AUC:', auc)\n",
    "print('Specificity:', spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e63a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "535/535 [==============================] - 6s 7ms/step - loss: 0.5845 - accuracy: 0.7133 - val_loss: 0.4204 - val_accuracy: 0.8357\n",
      "Epoch 2/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.4472 - accuracy: 0.8272 - val_loss: 0.3880 - val_accuracy: 0.8535\n",
      "Epoch 3/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.4028 - accuracy: 0.8452 - val_loss: 0.3629 - val_accuracy: 0.8624\n",
      "Epoch 4/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3782 - accuracy: 0.8566 - val_loss: 0.3587 - val_accuracy: 0.8672\n",
      "Epoch 5/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3648 - accuracy: 0.8604 - val_loss: 0.3489 - val_accuracy: 0.8676\n",
      "Epoch 6/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3595 - accuracy: 0.8629 - val_loss: 0.3463 - val_accuracy: 0.8691\n",
      "Epoch 7/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3546 - accuracy: 0.8640 - val_loss: 0.3393 - val_accuracy: 0.8714\n",
      "Epoch 8/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3500 - accuracy: 0.8686 - val_loss: 0.3394 - val_accuracy: 0.8722\n",
      "Epoch 9/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3424 - accuracy: 0.8686 - val_loss: 0.3414 - val_accuracy: 0.8703\n",
      "Epoch 10/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3394 - accuracy: 0.8695 - val_loss: 0.3386 - val_accuracy: 0.8703\n",
      "Epoch 11/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3365 - accuracy: 0.8716 - val_loss: 0.3370 - val_accuracy: 0.8713\n",
      "Epoch 12/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3307 - accuracy: 0.8743 - val_loss: 0.3365 - val_accuracy: 0.8724\n",
      "Epoch 13/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3349 - accuracy: 0.8732 - val_loss: 0.3361 - val_accuracy: 0.8718\n",
      "Epoch 14/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3351 - accuracy: 0.8728 - val_loss: 0.3383 - val_accuracy: 0.8744\n",
      "Epoch 15/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3304 - accuracy: 0.8740 - val_loss: 0.3357 - val_accuracy: 0.8732\n",
      "Epoch 16/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3268 - accuracy: 0.8747 - val_loss: 0.3386 - val_accuracy: 0.8736\n",
      "Epoch 17/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3251 - accuracy: 0.8763 - val_loss: 0.3365 - val_accuracy: 0.8748\n",
      "Epoch 18/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3215 - accuracy: 0.8778 - val_loss: 0.3405 - val_accuracy: 0.8734\n",
      "Epoch 19/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3228 - accuracy: 0.8766 - val_loss: 0.3423 - val_accuracy: 0.8736\n",
      "Epoch 20/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3205 - accuracy: 0.8788 - val_loss: 0.3392 - val_accuracy: 0.8760\n",
      "Epoch 21/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3208 - accuracy: 0.8788 - val_loss: 0.3398 - val_accuracy: 0.8754\n",
      "Epoch 22/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3202 - accuracy: 0.8784 - val_loss: 0.3390 - val_accuracy: 0.8767\n",
      "Epoch 23/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3197 - accuracy: 0.8780 - val_loss: 0.3418 - val_accuracy: 0.8764\n",
      "Epoch 24/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3193 - accuracy: 0.8783 - val_loss: 0.3394 - val_accuracy: 0.8743\n",
      "Epoch 25/50\n",
      "535/535 [==============================] - 4s 8ms/step - loss: 0.3188 - accuracy: 0.8797 - val_loss: 0.3355 - val_accuracy: 0.8751\n",
      "Epoch 26/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3169 - accuracy: 0.8784 - val_loss: 0.3387 - val_accuracy: 0.8740\n",
      "Epoch 27/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3183 - accuracy: 0.8796 - val_loss: 0.3341 - val_accuracy: 0.8769\n",
      "Epoch 28/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3136 - accuracy: 0.8808 - val_loss: 0.3418 - val_accuracy: 0.8752\n",
      "Epoch 29/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3175 - accuracy: 0.8804 - val_loss: 0.3361 - val_accuracy: 0.8734\n",
      "Epoch 30/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3172 - accuracy: 0.8799 - val_loss: 0.3393 - val_accuracy: 0.8759\n",
      "Epoch 31/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3149 - accuracy: 0.8808 - val_loss: 0.3430 - val_accuracy: 0.8769\n",
      "Epoch 32/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3153 - accuracy: 0.8808 - val_loss: 0.3452 - val_accuracy: 0.8749\n",
      "Epoch 33/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3096 - accuracy: 0.8814 - val_loss: 0.3423 - val_accuracy: 0.8763\n",
      "Epoch 34/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3147 - accuracy: 0.8813 - val_loss: 0.3377 - val_accuracy: 0.8739\n",
      "Epoch 35/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3136 - accuracy: 0.8815 - val_loss: 0.3496 - val_accuracy: 0.8752\n",
      "Epoch 36/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3110 - accuracy: 0.8814 - val_loss: 0.3421 - val_accuracy: 0.8748\n",
      "Epoch 37/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3113 - accuracy: 0.8809 - val_loss: 0.3439 - val_accuracy: 0.8743\n",
      "Epoch 38/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3088 - accuracy: 0.8819 - val_loss: 0.3503 - val_accuracy: 0.8754\n",
      "Epoch 39/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3062 - accuracy: 0.8837 - val_loss: 0.3452 - val_accuracy: 0.8748\n",
      "Epoch 40/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3096 - accuracy: 0.8825 - val_loss: 0.3479 - val_accuracy: 0.8767\n",
      "Epoch 41/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3094 - accuracy: 0.8829 - val_loss: 0.3508 - val_accuracy: 0.8770\n",
      "Epoch 42/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3096 - accuracy: 0.8832 - val_loss: 0.3474 - val_accuracy: 0.8774\n",
      "Epoch 43/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3032 - accuracy: 0.8844 - val_loss: 0.3470 - val_accuracy: 0.8766\n",
      "Epoch 44/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3083 - accuracy: 0.8828 - val_loss: 0.3463 - val_accuracy: 0.8771\n",
      "Epoch 45/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3113 - accuracy: 0.8818 - val_loss: 0.3380 - val_accuracy: 0.8773\n",
      "Epoch 46/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3021 - accuracy: 0.8839 - val_loss: 0.3403 - val_accuracy: 0.8763\n",
      "Epoch 47/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3050 - accuracy: 0.8829 - val_loss: 0.3433 - val_accuracy: 0.8762\n",
      "Epoch 48/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3007 - accuracy: 0.8857 - val_loss: 0.3471 - val_accuracy: 0.8751\n",
      "Epoch 49/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3052 - accuracy: 0.8843 - val_loss: 0.3435 - val_accuracy: 0.8770\n",
      "Epoch 50/50\n",
      "535/535 [==============================] - 4s 7ms/step - loss: 0.3022 - accuracy: 0.8866 - val_loss: 0.3433 - val_accuracy: 0.8764\n",
      "230/230 [==============================] - 1s 3ms/step\n",
      "Accuracy: 0.8764489294967953\n",
      "Precision: 0.9847457627118644\n",
      "Recall: 0.7276142767689417\n",
      "F1-score: 0.836874324810947\n",
      "ROC AUC: 0.8914647738125802\n",
      "Specificity: 0.9913022469195458\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary values\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "# Calculate metrics\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_binary).ravel()\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "auc_score = auc(fpr, tpr)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1_score}\")\n",
    "print(f\"ROC AUC: {auc_score}\")\n",
    "print(f\"Specificity: {specificity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "919e5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 1s 2ms/step\n",
      "Test Loss: 0.6854432821273804\n",
      "Test Accuracy: 0.5621011257171631\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n",
      "Test F1 score: 0.0\n",
      "Test ROC AUC score: 0.5\n",
      "Test Specificity: 1.0\n",
      "255/255 [==============================] - 1s 2ms/step\n",
      "Test Loss: 0.6844042539596558\n",
      "Test Accuracy: 0.5660979747772217\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n",
      "Test F1 score: 0.0\n",
      "Test ROC AUC score: 0.5\n",
      "Test Specificity: 1.0\n",
      "255/255 [==============================] - 1s 2ms/step\n",
      "Test Loss: 0.6853557825088501\n",
      "Test Accuracy: 0.562415599822998\n",
      "Test Precision: 0.0\n",
      "Test Recall: 0.0\n",
      "Test F1 score: 0.0\n",
      "Test ROC AUC score: 0.5\n",
      "Test Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from keras import backend as K\n",
    "\n",
    "X=df.drop('label', axis=1)\n",
    "y=df['label']\n",
    "X = X.values\n",
    "\n",
    "# define metrics\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true)*(1-y_pred), 0, 1)))\n",
    "    true_positives = K.sum(K.round(K.clip(y_true*y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true*(1-y_pred), 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip((1-y_true)*y_pred, 0, 1)))\n",
    "    specificity = true_negatives/(true_negatives+false_positives+K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "\n",
    "def confusion_matrix_tf(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(tf.round(y_pred), tf.int32)\n",
    "    values, indices, counts = tf.unique_with_counts(tf.stack([y_true, y_pred], axis=1))\n",
    "    num_classes = tf.shape(values)[0]\n",
    "    cm = tf.zeros((num_classes, num_classes), dtype=tf.int32)\n",
    "    updates = tf.reshape(counts, (-1,))\n",
    "    indices = tf.unstack(indices, axis=1)\n",
    "    cm = tf.tensor_scatter_nd_add(cm, indices, updates)\n",
    "    return cm\n",
    "\n",
    "# define MLP model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), \n",
    "              tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), specificity])\n",
    "\n",
    "# define cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# train and evaluate model using cross-validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, verbose=0)\n",
    "    loss, accuracy, precision, recall, auc, specificity = model.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = np.round(model.predict(X_test))\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('Test Loss:', loss)\n",
    "    print('Test Accuracy:', accuracy)\n",
    "    print('Test Precision:', precision)\n",
    "    print('Test Recall:', recall)\n",
    "    print('Test F1 score:', f1)\n",
    "    print('Test ROC AUC score:', auc)\n",
    "    print('Test Specificity:', specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c80681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 1s 2ms/step\n",
      "255/255 [==============================] - 1s 2ms/step\n",
      "255/255 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.563\n",
      "Precision: 0.222\n",
      "Recall: 0.000\n",
      "ROC AUC: 0.500\n",
      "Specificity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHANMUKH\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Define the evaluation metrics\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn = confusion_matrix(y_true, y_pred)[0, 0]\n",
    "    fp = confusion_matrix(y_true, y_pred)[0, 1]\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "X=df.drop('label', axis=1)\n",
    "y=df['label']\n",
    "X = X.values\n",
    "\n",
    "# Define the MLP model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the K-Fold cross-validator\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "roc_auc_scores = []\n",
    "specificity_scores = []\n",
    "\n",
    "# Loop over the folds\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    # Split the data into train and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create and fit the model on the train set\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = np.round(model.predict(X_test)).flatten()\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    specificity = specificity_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the evaluation metrics for this fold to the lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "# Compute and print the average evaluation metrics over all folds\n",
    "print('Accuracy: {:.3f}'.format(np.mean(accuracy_scores)))\n",
    "print('Precision: {:.3f}'.format(np.mean(precision_scores)))\n",
    "print('Recall: {:.3f}'.format(np.mean(recall_scores)))\n",
    "print('ROC AUC: {:.3f}'.format(np.mean(roc_auc_scores)))\n",
    "print('Specificity: {:.3f}'.format(np.mean(specificity_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec58c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
